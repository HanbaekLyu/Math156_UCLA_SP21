{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Network for MNIST image classficiation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# from sklearn.utils.extmath import softmax\n",
    "from matplotlib import pyplot as plt\n",
    "import re\n",
    "from tqdm import trange\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "plt.rcParams['font.serif'] = ['Times New Roman'] + plt.rcParams['font.serif']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from src.CNN import CNN, compute_accuracy_metrics, multiclass_accuracy_metrics, list2onehot, onehot2list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape (70000, 784)\n",
      "y.shape (70000,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nEach row of X is a vectroization of an image of 28 x 28 = 784 pixels.  \\nThe corresponding row of y holds the true class label from {0,1, .. , 9}.\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data from https://www.openml.org/d/554\n",
    "X, y = fetch_openml('mnist_784', version=1, return_X_y=True)\n",
    "# X = X.values  ### Uncomment this line if you are having type errors in plotting. It is loading as a pandas dataframe, but our indexing is for numpy array. \n",
    "X = X / 255.\n",
    "\n",
    "print('X.shape', X.shape)\n",
    "print('y.shape', y.shape)\n",
    "\n",
    "'''\n",
    "Each row of X is a vectroization of an image of 28 x 28 = 784 pixels.  \n",
    "The corresponding row of y holds the true class label from {0,1, .. , 9}.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_padding(img, thickness=1):\n",
    "    # img = a x b image \n",
    "    [a,b] = img.shape\n",
    "    Y = np.zeros(shape=[a+thickness, b+thickness])\n",
    "    r_loc = np.random.choice(np.arange(thickness+1))\n",
    "    c_loc = np.random.choice(np.arange(thickness+1))\n",
    "    Y[r_loc:r_loc+a, c_loc:c_loc+b] = img\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_multiclass_MNIST_padding(list_digits=['0','1', '2'], full_MNIST=[X,y], padding_thickness=10):\n",
    "    # get train and test set from MNIST of given digits\n",
    "    # e.g., list_digits = ['0', '1', '2']\n",
    "    # pad each 28 x 28 image with zeros so that it has now \"padding_thickness\" more rows and columns\n",
    "    # The original image is superimposed at a uniformly chosen location \n",
    "    if full_MNIST is not None:\n",
    "        X, y = full_MNIST\n",
    "    else:\n",
    "        X, y = fetch_openml('mnist_784', version=1, return_X_y=True)\n",
    "        X = X / 255.\n",
    "    Y = list2onehot(y.tolist(), list_digits)\n",
    "    \n",
    "    idx = [i for i in np.arange(len(y)) if y[i] in list_digits] # list of indices where the label y is in list_digits\n",
    "    \n",
    "    X01 = X[idx,:]\n",
    "    y01 = Y[idx,:]\n",
    "\n",
    "    X_train = []\n",
    "    X_test = []\n",
    "    y_test = [] # list of one-hot encodings (indicator vectors) of each label  \n",
    "    y_train = [] # list of one-hot encodings (indicator vectors) of each label  \n",
    "\n",
    "    for i in trange(X01.shape[0]):\n",
    "        # for each example i, make it into train set with probabiliy 0.8 and into test set otherwise \n",
    "        U = np.random.rand() # Uniform([0,1]) variable\n",
    "        img_padded = random_padding(X01[i,:].reshape(28,28), thickness=padding_thickness)\n",
    "        img_padded_vec = img_padded.reshape(1,-1)\n",
    "        if U<0.8:\n",
    "            X_train.append(img_padded_vec[0,:].copy())\n",
    "            y_train.append(y01[i,:].copy())\n",
    "        else:\n",
    "            X_test.append(img_padded_vec[0,:].copy())\n",
    "            y_test.append(y01[i,:].copy())\n",
    "\n",
    "    X_train = np.asarray(X_train)\n",
    "    X_test = np.asarray(X_test)\n",
    "    y_train = np.asarray(y_train)\n",
    "    y_test = np.asarray(y_test)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple MNIST binary classification experiments \n",
    "\n",
    "X_train, X_test, y_train, y_test = sample_multiclass_MNIST_padding(list_digits=['0','1'], \n",
    "                                                                   full_MNIST=[X,y],\n",
    "                                                                   padding_thickness=0)\n",
    "\n",
    "# data subsampling \n",
    "train_size = 100\n",
    "\n",
    "idx = np.random.choice(np.arange(len(y_train)), train_size)\n",
    "X_train0 = X_train[idx, :]/np.max(X_train)\n",
    "y_train0 = y_train[idx, :]\n",
    "\n",
    "# preprocessing \n",
    "out = []\n",
    "# populate the tuple list with the data\n",
    "for i in range(X_train0.shape[0]):\n",
    "    item = list((X_train0[i,:].reshape(1,28,28), y_train0[i,:])) \n",
    "    out.append(item)\n",
    "    \n",
    "# FFNN training\n",
    "CNN0 = CNN(training_data = out,\n",
    "           f = 5, # conv filter dim\n",
    "           f_pool = 2, # maxpool filter dim\n",
    "           num_filt1 = 8, # num filters for the first conv layer\n",
    "           num_filt2 = 8, # num filters for the second conv layer\n",
    "           conv_stride = 1,\n",
    "           pool_stride = 2,\n",
    "           hidden_nodes = 128)\n",
    "\n",
    "CNN0.train(lr = 0.01,\n",
    "           beta1 = 0.95,\n",
    "           beta2 = 0.99,\n",
    "           minibatch_size = 32,\n",
    "           num_epochs = 20,\n",
    "           verbose = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN prediction\n",
    "\n",
    "X_test /= np.max(X_test)\n",
    "print('X_test.shape', X_test.shape)\n",
    "out_test = []\n",
    "\n",
    "\n",
    "for i in range(X_test.shape[0]):\n",
    "    out_test.append((X_test[i,:].reshape(1,28,28)))\n",
    "                \n",
    "y_hat = CNN0.predict(image_list=out_test)\n",
    "\n",
    "y_test_label = np.asarray(onehot2list(y_test))\n",
    "P_pred = np.asarray([p[1] for p in y_hat])\n",
    "\n",
    "compute_accuracy_metrics(Y_test=y_test_label, P_pred=P_pred, use_opt_threshold=False, verbose=True)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple MNIST binary classification experiments \n",
    "\n",
    "thickness = 10\n",
    "X_train, X_test, y_train, y_test = sample_multiclass_MNIST_padding(list_digits=['0','1'], \n",
    "                                                                   full_MNIST=[X,y],\n",
    "                                                                   padding_thickness=thickness)\n",
    "\n",
    "# data subsampling \n",
    "train_size = 100\n",
    "\n",
    "idx = np.random.choice(np.arange(len(y_train)), train_size)\n",
    "X_train0 = X_train[idx, :]/np.max(X_train)\n",
    "y_train0 = y_train[idx, :]\n",
    "\n",
    "# preprocessing \n",
    "out = []\n",
    "# populate the tuple list with the data\n",
    "for i in range(X_train0.shape[0]):\n",
    "    item = list((X_train0[i,:].reshape(1,28+thickness,28+thickness), y_train0[i,:])) \n",
    "    out.append(item)\n",
    "    \n",
    "# FFNN training\n",
    "CNN0 = CNN(training_data = out,\n",
    "           f = 5, # conv filter dim\n",
    "           f_pool = 2, # maxpool filter dim\n",
    "           num_filt1 = 8, # num filters for the first conv layer\n",
    "           num_filt2 = 8, # num filters for the second conv layer\n",
    "           conv_stride = 1,\n",
    "           pool_stride = 2,\n",
    "           hidden_nodes = 128)\n",
    "\n",
    "CNN0.train(lr = 0.01,\n",
    "           beta1 = 0.95,\n",
    "           beta2 = 0.99,\n",
    "           minibatch_size = 32,\n",
    "           num_epochs = 30,\n",
    "           verbose = True)\n",
    "\n",
    "# CNN prediction\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "idx = np.random.choice(np.arange(len(y_test)), 100)\n",
    "X_test0 = X_test[idx, :]/np.max(X_test)\n",
    "y_test0 = y_test[idx, :]\n",
    "\n",
    "out_test = []\n",
    "\n",
    "for i in range(X_test0.shape[0]):\n",
    "    out_test.append((X_test0[i,:].reshape(1,28+thickness,28+thickness)))\n",
    "                \n",
    "y_hat = CNN0.predict(image_list=out_test)\n",
    "\n",
    "y_test_label = np.asarray(onehot2list(y_test0))\n",
    "P_pred = np.asarray([p[1] for p in y_hat])\n",
    "\n",
    "compute_accuracy_metrics(Y_test=y_test_label, P_pred=P_pred, use_opt_threshold=False, verbose=True)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute comparative multiclass classification metrics on test data\n",
    "\n",
    "thinkness = 10\n",
    "n_filters = [2, 5, 10, 15, 20]\n",
    "list_digits=['0','1','2','3','4']\n",
    "\n",
    "# Data preprocessing\n",
    "\n",
    "X_train, X_test, y_train, y_test = sample_multiclass_MNIST_padding(list_digits=['0','1'], \n",
    "                                                                   full_MNIST=[X,y],\n",
    "                                                                   padding_thickness=thinkness)\n",
    "train_size_list = [10, 50, 100]\n",
    "\n",
    "# make plot\n",
    "ncols = len(train_size_list)\n",
    "fig, ax = plt.subplots(nrows=1, ncols=ncols, figsize=[13,5])\n",
    "\n",
    "for t in np.arange(len(train_size_list)):\n",
    "    accuracy_list_test = []\n",
    "    accuracy_list_train = []\n",
    "    \n",
    "    train_size = train_size_list[t]\n",
    "    idx = np.random.choice(np.arange(len(y_train)), train_size)\n",
    "    X_train0 = X_train[idx, :]/np.max(X_train)\n",
    "    y_train0 = y_train[idx, :]\n",
    "    \n",
    "    idx = np.random.choice(np.arange(len(y_test)), 200)\n",
    "    X_test0 = X_test[idx, :]/np.max(X_test)\n",
    "    y_test0 = y_test[idx, :]\n",
    "\n",
    "    out = []\n",
    "    out_train = []\n",
    "    # populate the tuple list with the data\n",
    "    for i in range(X_train0.shape[0]):\n",
    "        item = list((X_train0[i,:].reshape(1,28+thinkness,28+thinkness), y_train0[i,:])) \n",
    "        out.append(item)\n",
    "        out_train.append(X_train0[i,:].reshape(1,28+thinkness,28+thinkness))\n",
    "        \n",
    "    X_test /= np.max(X_test)\n",
    "    out_test = []\n",
    "    for i in range(X_test0.shape[0]):\n",
    "        out_test.append((X_test0[i,:].reshape(1,28+thinkness,28+thinkness)))\n",
    "\n",
    "    for M in n_filters:\n",
    "\n",
    "        # FFNN training\n",
    "        CNN0 = CNN(training_data = out,\n",
    "           f = 5, # conv filter dim\n",
    "           f_pool = 2, # maxpool filter dim\n",
    "           num_filt1 = M, # num filters for the first conv layer\n",
    "           num_filt2 = M, # num filters for the second conv layer\n",
    "           conv_stride = 1,\n",
    "           pool_stride = 2,\n",
    "           hidden_nodes = 128)\n",
    "\n",
    "        CNN0.train(lr = 0.01,\n",
    "                   beta1 = 0.95,\n",
    "                   beta2 = 0.99,\n",
    "                   minibatch_size = 32,\n",
    "                   num_epochs = 50,\n",
    "                   verbose = True)\n",
    "        \n",
    "        # FFNN prediction\n",
    "        print()\n",
    "        y_hat_train = np.asarray(CNN0.predict(out_train))\n",
    "        y_hat_test = np.asarray(CNN0.predict(out_test))\n",
    "\n",
    "        y_train_label = np.asarray(onehot2list(y_train0))\n",
    "        y_test_label = np.asarray(onehot2list(y_test0))\n",
    "\n",
    "        results_train = multiclass_accuracy_metrics(Y_test=y_train0, P_pred=y_hat_train)\n",
    "        results_test = multiclass_accuracy_metrics(Y_test=y_test0, P_pred=y_hat_test)\n",
    "\n",
    "        accuracy_list_train.append(results_train.get('Accuracy'))\n",
    "        accuracy_list_test.append(results_test.get('Accuracy'))\n",
    "    \n",
    "    ## Plot\n",
    "    ax[t].plot(n_filters, accuracy_list_train, color='blue', label=\"train accuracy\")\n",
    "    ax[t].plot(n_filters, accuracy_list_test, color='red', label=\"test accuracy\")\n",
    "    ax[t].set_xlabel('Number of filters', fontsize=15)\n",
    "    ax[t].set_ylabel('Classification Accuracy', fontsize=15)\n",
    "    ax[t].title.set_text(\"num training ex = %i\" % (train_size)) \n",
    "    ax[t].legend(fontsize=15)\n",
    "            \n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.9])\n",
    "plt.savefig('MNIST_CNN_accuracy_ex1.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying non-aligned MNIST images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35735/35735 [00:00<00:00, 68599.00it/s]\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.img_x_dim 28\n",
      "LR:0.01, MiniBatch Size:32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 1/50 [00:05<04:53,  5.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0, error 1.60961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 6/50 [00:36<04:33,  6.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 5, error 1.60556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 11/50 [01:09<04:15,  6.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 10, error 1.42179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 16/50 [01:43<03:48,  6.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 15, error 1.02099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 21/50 [02:17<03:17,  6.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 20, error 0.60103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 26/50 [02:51<02:44,  6.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 25, error 0.32333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 31/50 [03:26<02:10,  6.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 30, error 0.33046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 36/50 [04:00<01:36,  6.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 35, error 0.02560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 41/50 [04:35<01:02,  6.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 40, error 0.08078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 46/50 [05:09<00:27,  6.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 45, error 0.21739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [05:37<00:00,  6.75s/it]\n",
      "  2%|▏         | 2/100 [00:00<00:09, 10.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:09<00:00, 10.70it/s]\n",
      "100%|██████████| 100/100 [00:09<00:00, 10.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!!! confusion_mx [[23  0  0  0  0]\n",
      " [ 0 21  0  0  0]\n",
      " [ 0  0 21  0  0]\n",
      " [ 1  0  0 21  0]\n",
      " [ 0  0  0  0 13]]\n",
      "!!! Accuracy 0.99\n",
      "!!! confusion_mx [[21  0  0  0  0]\n",
      " [ 0 24  1  1  0]\n",
      " [ 4  0 12  2  0]\n",
      " [ 2  0  0  9  0]\n",
      " [ 4  1  0  1 18]]\n",
      "!!! Accuracy 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35735/35735 [00:00<00:00, 58014.94it/s]\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.img_x_dim 35\n",
      "LR:0.01, MiniBatch Size:32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 1/50 [00:11<09:00, 11.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0, error 1.60927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 6/50 [01:05<07:56, 10.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 5, error 1.60604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 11/50 [01:58<06:59, 10.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 10, error 1.48704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 16/50 [02:52<06:06, 10.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 15, error 1.23380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 21/50 [03:46<05:13, 10.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 20, error 0.93506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 26/50 [04:40<04:19, 10.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 25, error 1.03427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 31/50 [05:34<03:24, 10.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 30, error 0.77698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 36/50 [06:30<02:38, 11.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 35, error 0.50079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 41/50 [07:30<01:47, 11.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 40, error 0.42956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 46/50 [08:32<00:49, 12.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 45, error 0.46880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 48/50 [08:58<00:22, 11.22s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-0581f97e163b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     59\u001b[0m            hidden_nodes = 128)\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         CNN0.train(lr = 0.01,\n\u001b[0m\u001b[1;32m     62\u001b[0m                    \u001b[0mbeta1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.95\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m                    \u001b[0mbeta2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.99\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/OneDrive/PycharmProjects/Math156_UCLA_SP21/src/CNN.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, lr, beta1, beta2, minibatch_size, num_epochs, verbose, save_path)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m             \u001b[0;31m# update parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m             params, cost = self.adamGD(minibatch=[X,Y],\n\u001b[0m\u001b[1;32m    310\u001b[0m                                        \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# learning rate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m                                        \u001b[0mbeta1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/OneDrive/PycharmProjects/Math156_UCLA_SP21/src/CNN.py\u001b[0m in \u001b[0;36madamGD\u001b[0;34m(self, minibatch, lr, beta1, beta2, cost)\u001b[0m\n\u001b[1;32m    218\u001b[0m             \u001b[0;31m# stride for maxpool = 2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m             \u001b[0;31m# maxpool filter dim = 2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m             \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m             \u001b[0;34m[\u001b[0m\u001b[0mdf1_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf2_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdw3_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdw4_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdb1_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdb2_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdb3_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdb4_\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/OneDrive/PycharmProjects/Math156_UCLA_SP21/src/CNN.py\u001b[0m in \u001b[0;36mconv\u001b[0;34m(self, image, label)\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0mdconv2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m<=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;31m# backpropagate through ReLU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         \u001b[0mdconv1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdb2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvolutionBackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdconv2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconv1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconv_s\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# backpropagate previous gradient through second convolutional layer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m         \u001b[0mdconv1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m<=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;31m# backpropagate through ReLU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/OneDrive/PycharmProjects/Math156_UCLA_SP21/src/CNN.py\u001b[0m in \u001b[0;36mconvolutionBackward\u001b[0;34m(self, dconv_prev, conv_in, filt, s)\u001b[0m\n\u001b[1;32m    411\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0mcurr_x\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mf\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0morig_dim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m                     \u001b[0;31m# loss gradient of filter (used to update the filter)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 413\u001b[0;31m                     \u001b[0mdfilt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcurr_f\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mdconv_prev\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcurr_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_x\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mconv_in\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurr_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mcurr_y\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurr_x\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mcurr_x\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    414\u001b[0m                     \u001b[0;31m# loss gradient of the input to the convolution operation (conv1 in the case of this network)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m                     \u001b[0mdout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurr_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mcurr_y\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurr_x\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mcurr_x\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mdconv_prev\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcurr_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_x\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mfilt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcurr_f\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 936x360 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# compute comparative multiclass classification metrics on test data\n",
    "\n",
    "padding_list = [0, 7, 13, 20]\n",
    "list_digits=['0','1','2','3','4']\n",
    "\n",
    "## Train\n",
    "train_size_list = [50, 100, 200]\n",
    "\n",
    "# make plot\n",
    "ncols = len(train_size_list)\n",
    "fig, ax = plt.subplots(nrows=1, ncols=ncols, figsize=[13,5])\n",
    "\n",
    "for t in np.arange(len(train_size_list)):\n",
    "    accuracy_list_test = []\n",
    "    accuracy_list_train = []\n",
    "    \n",
    "    train_size = train_size_list[t]\n",
    "    \n",
    "    for thickness in padding_list:\n",
    "        # Data preprocessing\n",
    "        X_train, X_test, y_train, y_test = sample_multiclass_MNIST_padding(list_digits=list_digits, \n",
    "                                                                           full_MNIST=[X,y], \n",
    "                                                                           padding_thickness=thickness)\n",
    "            \n",
    "        idx = np.random.choice(np.arange(len(y_train)), train_size)\n",
    "        X_train0 = X_train[idx, :]/np.max(X_train)\n",
    "        y_train0 = y_train[idx, :]\n",
    "\n",
    "        \n",
    "        \n",
    "        idx = np.random.choice(np.arange(len(y_test)), 100)\n",
    "        X_test0 = X_test[idx, :]/np.max(X_test)\n",
    "        y_test0 = y_test[idx, :]\n",
    "\n",
    "        out = []\n",
    "        out_train = []\n",
    "        # populate the tuple list with the data\n",
    "        for i in range(X_train0.shape[0]):\n",
    "            item = list((X_train0[i,:].reshape(1, 28+thickness, 28+thickness), y_train0[i,:])) \n",
    "            \n",
    "            out.append(item)\n",
    "            out_train.append(X_train0[i,:].reshape(1, 28+thickness, 28+thickness))\n",
    "\n",
    "        X_test /= np.max(X_test)\n",
    "        out_test = []\n",
    "        for i in range(X_test0.shape[0]):\n",
    "            out_test.append((X_test0[i,:].reshape(1, 28+thickness, 28+thickness)))\n",
    "    \n",
    "    \n",
    "    \n",
    "        # FFNN training\n",
    "        CNN0 = CNN(training_data = out,\n",
    "           f = 5, # conv filter dim\n",
    "           f_pool = 2, # maxpool filter dim\n",
    "           num_filt1 = 10, # num filters for the first conv layer\n",
    "           num_filt2 = 10, # num filters for the second conv layer\n",
    "           conv_stride = 1,\n",
    "           pool_stride = 2,\n",
    "           hidden_nodes = 128)\n",
    "\n",
    "        CNN0.train(lr = 0.01,\n",
    "                   beta1 = 0.95,\n",
    "                   beta2 = 0.99,\n",
    "                   minibatch_size = 32,\n",
    "                   num_epochs = 50,\n",
    "                   verbose = True)\n",
    "\n",
    "        # FFNN prediction\n",
    "        print()\n",
    "        y_hat_train = np.asarray(CNN0.predict(out_train))\n",
    "        y_hat_test = np.asarray(CNN0.predict(out_test))\n",
    "\n",
    "        y_train_label = np.asarray(onehot2list(y_train0))\n",
    "        y_test_label = np.asarray(onehot2list(y_test0))\n",
    "\n",
    "        results_train = multiclass_accuracy_metrics(Y_test=y_train0, P_pred=y_hat_train)\n",
    "        results_test = multiclass_accuracy_metrics(Y_test=y_test0, P_pred=y_hat_test)\n",
    "\n",
    "        accuracy_list_train.append(results_train.get('Accuracy'))\n",
    "        accuracy_list_test.append(results_test.get('Accuracy'))\n",
    "    \n",
    "    ## Plot\n",
    "    ax[t].plot(padding_list, accuracy_list_train, color='blue', label=\"train accuracy\")\n",
    "    ax[t].plot(padding_list, accuracy_list_test, color='red', label=\"test accuracy\")\n",
    "    ax[t].set_xlabel('Padding thickness', fontsize=15)\n",
    "    ax[t].set_ylabel('Classification Accuracy', fontsize=15)\n",
    "    ax[t].title.set_text(\"num training ex = %i\" % (train_size)) \n",
    "    ax[t].legend(fontsize=15)\n",
    "            \n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.9])\n",
    "plt.savefig('MNIST_CNN_accuracy_padding_ex2.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "colourgraphenv",
   "language": "python",
   "name": "colourgraphenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
