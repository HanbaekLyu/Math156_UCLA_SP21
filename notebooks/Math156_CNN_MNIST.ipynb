{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Network for MNIST image classficiation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# from sklearn.utils.extmath import softmax\n",
    "from matplotlib import pyplot as plt\n",
    "import re\n",
    "from tqdm import trange\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "plt.rcParams['font.serif'] = ['Times New Roman'] + plt.rcParams['font.serif']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from src.CNN import CNN, compute_accuracy_metrics, multiclass_accuracy_metrics, list2onehot, onehot2list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape (70000, 784)\n",
      "y.shape (70000,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nEach row of X is a vectroization of an image of 28 x 28 = 784 pixels.  \\nThe corresponding row of y holds the true class label from {0,1, .. , 9}.\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data from https://www.openml.org/d/554\n",
    "X, y = fetch_openml('mnist_784', version=1, return_X_y=True)\n",
    "# X = X.values  ### Uncomment this line if you are having type errors in plotting. It is loading as a pandas dataframe, but our indexing is for numpy array. \n",
    "X = X / 255.\n",
    "\n",
    "print('X.shape', X.shape)\n",
    "print('y.shape', y.shape)\n",
    "\n",
    "'''\n",
    "Each row of X is a vectroization of an image of 28 x 28 = 784 pixels.  \n",
    "The corresponding row of y holds the true class label from {0,1, .. , 9}.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_padding(img, thickness=1):\n",
    "    # img = a x b image \n",
    "    [a,b] = img.shape\n",
    "    Y = np.zeros(shape=[a+thickness, b+thickness])\n",
    "    r_loc = np.random.choice(np.arange(thickness+1))\n",
    "    c_loc = np.random.choice(np.arange(thickness+1))\n",
    "    Y[r_loc:r_loc+a, c_loc:c_loc+b] = img\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_multiclass_MNIST_padding(list_digits=['0','1', '2'], full_MNIST=[X,y], padding_thickness=10):\n",
    "    # get train and test set from MNIST of given digits\n",
    "    # e.g., list_digits = ['0', '1', '2']\n",
    "    # pad each 28 x 28 image with zeros so that it has now \"padding_thickness\" more rows and columns\n",
    "    # The original image is superimposed at a uniformly chosen location \n",
    "    if full_MNIST is not None:\n",
    "        X, y = full_MNIST\n",
    "    else:\n",
    "        X, y = fetch_openml('mnist_784', version=1, return_X_y=True)\n",
    "        X = X / 255.\n",
    "    Y = list2onehot(y.tolist(), list_digits)\n",
    "    \n",
    "    idx = [i for i in np.arange(len(y)) if y[i] in list_digits] # list of indices where the label y is in list_digits\n",
    "    \n",
    "    X01 = X[idx,:]\n",
    "    y01 = Y[idx,:]\n",
    "\n",
    "    X_train = []\n",
    "    X_test = []\n",
    "    y_test = [] # list of one-hot encodings (indicator vectors) of each label  \n",
    "    y_train = [] # list of one-hot encodings (indicator vectors) of each label  \n",
    "\n",
    "    for i in trange(X01.shape[0]):\n",
    "        # for each example i, make it into train set with probabiliy 0.8 and into test set otherwise \n",
    "        U = np.random.rand() # Uniform([0,1]) variable\n",
    "        img_padded = random_padding(X01[i,:].reshape(28,28), thickness=padding_thickness)\n",
    "        img_padded_vec = img_padded.reshape(1,-1)\n",
    "        if U<0.8:\n",
    "            X_train.append(img_padded_vec[0,:].copy())\n",
    "            y_train.append(y01[i,:].copy())\n",
    "        else:\n",
    "            X_test.append(img_padded_vec[0,:].copy())\n",
    "            y_test.append(y01[i,:].copy())\n",
    "\n",
    "    X_train = np.asarray(X_train)\n",
    "    X_test = np.asarray(X_test)\n",
    "    y_train = np.asarray(y_train)\n",
    "    y_test = np.asarray(y_test)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14780/14780 [00:00<00:00, 69324.16it/s]\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.img_x_dim 28\n",
      "LR:0.01, MiniBatch Size:32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|▌         | 1/20 [00:13<04:09, 13.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, error 0.68319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 6/20 [01:22<03:11, 13.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5, error 0.00550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 11/20 [02:29<02:00, 13.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10, error 0.00130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 16/20 [03:36<00:53, 13.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 15, error 0.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [04:30<00:00, 13.51s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6929733938846571,\n",
       " 0.6918562485465631,\n",
       " 0.6904260642057084,\n",
       " 0.6831942169447871,\n",
       " 0.6868666612370352,\n",
       " 0.676298237763575,\n",
       " 0.6657675986021263,\n",
       " 0.6501132877805668,\n",
       " 0.6291817297287418,\n",
       " 0.49803891812791234,\n",
       " 0.38397250399525423,\n",
       " 0.21801315238603333,\n",
       " 0.3223975969405526,\n",
       " 0.25380070478148015,\n",
       " 0.17994705288725238,\n",
       " 0.08607542651736297,\n",
       " 0.09994003802593404,\n",
       " 0.05094888884431475,\n",
       " 0.008934515870599534,\n",
       " 0.0035917860413124236,\n",
       " 0.024275094137032265,\n",
       " 0.14466825964707788,\n",
       " 0.033771416379130344,\n",
       " 0.005504562322544652,\n",
       " 0.0019153001690919232,\n",
       " 0.016474213876869995,\n",
       " 0.04149441830472472,\n",
       " 0.00017630173911288447,\n",
       " 0.0006359477710922226,\n",
       " 0.036248822040266034,\n",
       " 0.04100784849809748,\n",
       " 0.00013129322378678787,\n",
       " 0.03722950387938772,\n",
       " 0.014949126076977362,\n",
       " 0.0006452549854673071,\n",
       " 0.00011022044461057507,\n",
       " 0.00416131136547251,\n",
       " 0.0011229863934184082,\n",
       " 0.0018002351880005182,\n",
       " 2.189117454746979e-06,\n",
       " 0.0012091960287598832,\n",
       " 0.000740007819739482,\n",
       " 0.00016481057124758763,\n",
       " 0.0013026305647991544,\n",
       " 3.5350215403494777e-05,\n",
       " 0.00108276257621792,\n",
       " 0.00013892515625872455,\n",
       " 1.4828837361856354e-06,\n",
       " 0.0005468433823311008,\n",
       " 0.00012770110799271056,\n",
       " 0.0001338438166266607,\n",
       " 1.630464992949225e-05,\n",
       " 0.00010295324640347385,\n",
       " 5.977279046559982e-05,\n",
       " 0.000349610216853836,\n",
       " 0.0019253679921624202,\n",
       " 4.9279129824375615e-05,\n",
       " 0.0011607258202915413,\n",
       " 1.2032324105488252e-05,\n",
       " 4.764367141712802e-05,\n",
       " 0.0001675619870498228,\n",
       " 3.872905107841058e-06,\n",
       " 0.0002266199031898672,\n",
       " 4.845366330489116e-06,\n",
       " 4.790955639213622e-05,\n",
       " 0.00012838541242547765,\n",
       " 0.00017544193639905636,\n",
       " 1.2440621554205114e-05,\n",
       " 0.0001675769808334114,\n",
       " 9.054278712143844e-05,\n",
       " 4.545279692288823e-05,\n",
       " 1.5719062859869196e-05,\n",
       " 4.5234482855327466e-05,\n",
       " 0.00013491113399762835,\n",
       " 0.00011292374937645704,\n",
       " 7.369234340121147e-06,\n",
       " 1.0149330375283035e-05,\n",
       " 0.0001432067979978622,\n",
       " 0.00010865150072401146,\n",
       " 1.0488464122554163e-05]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simple MNIST binary classification experiments \n",
    "\n",
    "X_train, X_test, y_train, y_test = sample_multiclass_MNIST_padding(list_digits=['0','1'], \n",
    "                                                                   full_MNIST=[X,y],\n",
    "                                                                   padding_thickness=0)\n",
    "\n",
    "# data subsampling \n",
    "train_size = 100\n",
    "\n",
    "idx = np.random.choice(np.arange(len(y_train)), train_size)\n",
    "X_train0 = X_train[idx, :]/np.max(X_train)\n",
    "y_train0 = y_train[idx, :]\n",
    "\n",
    "# preprocessing \n",
    "out = []\n",
    "# populate the tuple list with the data\n",
    "for i in range(X_train0.shape[0]):\n",
    "    item = list((X_train0[i,:].reshape(1,28,28), y_train0[i,:])) \n",
    "    out.append(item)\n",
    "    \n",
    "# CNN training\n",
    "CNN0 = CNN(training_data = out,\n",
    "           f = 5, # conv filter dim\n",
    "           f_pool = 2, # maxpool filter dim\n",
    "           num_filt1 = 8, # num filters for the first conv layer\n",
    "           num_filt2 = 8, # num filters for the second conv layer\n",
    "           conv_stride = 1,\n",
    "           pool_stride = 2,\n",
    "           hidden_nodes = 128)\n",
    "\n",
    "CNN0.train(lr = 0.01,\n",
    "           beta1 = 0.95,\n",
    "           beta2 = 0.99,\n",
    "           minibatch_size = 32,\n",
    "           num_epochs = 20,\n",
    "           verbose = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/2965 [00:00<02:43, 18.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test.shape (2965, 784)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2965/2965 [02:39<00:00, 18.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC ===> 1.000\n",
      "Opt_threshold ===> 0.020\n",
      "Accuracy ===> 0.993\n",
      "Sensitivity ===> 0.998\n",
      "Specificity ===> 0.989\n",
      "Precision ===> 0.998\n",
      "Fall_out ===> 0.002\n",
      "Miss_rate ===> 0.011\n",
      "Confusion matrix  ===> \n",
      " [[1386    3]\n",
      " [  17 1559]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Y_test': array([1, 0, 1, ..., 1, 1, 1]),\n",
       " 'Y_pred': array([[1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        ...,\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.]]),\n",
       " 'AUC': 0.999877573245917,\n",
       " 'Opt_threshold': 0.019725187027058517,\n",
       " 'Accuracy': 0.9932546374367622,\n",
       " 'Sensitivity': 0.9978401727861771,\n",
       " 'Specificity': 0.9892131979695431,\n",
       " 'Precision': 0.9980793854033291,\n",
       " 'Fall_out': 0.0021598272138228943,\n",
       " 'Miss_rate': 0.010786802030456852,\n",
       " 'Confusion_mx': array([[1386,    3],\n",
       "        [  17, 1559]])}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CNN prediction\n",
    "\n",
    "X_test /= np.max(X_test)\n",
    "print('X_test.shape', X_test.shape)\n",
    "out_test = []\n",
    "\n",
    "\n",
    "for i in range(X_test.shape[0]):\n",
    "    out_test.append((X_test[i,:].reshape(1,28,28)))\n",
    "                \n",
    "y_hat = CNN0.predict(image_list=out_test)\n",
    "\n",
    "y_test_label = np.asarray(onehot2list(y_test))\n",
    "P_pred = np.asarray([p[1] for p in y_hat])\n",
    "\n",
    "compute_accuracy_metrics(Y_test=y_test_label, P_pred=P_pred, use_opt_threshold=False, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw Filters\n",
    "\n",
    "f1 = CNN0.params.get('f1')\n",
    "\n",
    "# make plot\n",
    "nrows = 2\n",
    "ncols = 4\n",
    "fig, ax = plt.subplots(nrows=2, ncols=ncols, figsize=[10,4.5])\n",
    "\n",
    "for i in np.arange(nrows):\n",
    "    for j in np.arange(ncols):\n",
    "        im = ax[i,j].imshow(f1[j + 4*i,0,:,:])\n",
    "        ax[i,j].set_xticks([])\n",
    "        ax[i,j].set_yticks([])\n",
    "        fig.colorbar(im, ax=ax[i,j], fraction=0.0457, pad=0.04)\n",
    "        \n",
    "fig.suptitle(\"Learned filters for the first convolutional layer\", fontsize=15)\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.9])\n",
    "plt.subplots_adjust(left=0.01, right=0.9, bottom=0.1, top=0.9, wspace=0.2, hspace=0.1)\n",
    "plt.savefig('MNIST_CNN_filter_ex1.pdf', bbox_inches=\"tight\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple MNIST binary classification experiments \n",
    "\n",
    "thickness = 10\n",
    "X_train, X_test, y_train, y_test = sample_multiclass_MNIST_padding(list_digits=['0','1'], \n",
    "                                                                   full_MNIST=[X,y],\n",
    "                                                                   padding_thickness=thickness)\n",
    "\n",
    "# data subsampling \n",
    "train_size = 100\n",
    "\n",
    "idx = np.random.choice(np.arange(len(y_train)), train_size)\n",
    "X_train0 = X_train[idx, :]/np.max(X_train)\n",
    "y_train0 = y_train[idx, :]\n",
    "\n",
    "# preprocessing \n",
    "out = []\n",
    "# populate the tuple list with the data\n",
    "for i in range(X_train0.shape[0]):\n",
    "    item = list((X_train0[i,:].reshape(1,28+thickness,28+thickness), y_train0[i,:])) \n",
    "    out.append(item)\n",
    "    \n",
    "# CNN training\n",
    "CNN0 = CNN(training_data = out,\n",
    "           f = 5, # conv filter dim\n",
    "           f_pool = 2, # maxpool filter dim\n",
    "           num_filt1 = 8, # num filters for the first conv layer\n",
    "           num_filt2 = 8, # num filters for the second conv layer\n",
    "           conv_stride = 1,\n",
    "           pool_stride = 2,\n",
    "           hidden_nodes = 128)\n",
    "\n",
    "CNN0.train(lr = 0.01,\n",
    "           beta1 = 0.95,\n",
    "           beta2 = 0.99,\n",
    "           minibatch_size = 32,\n",
    "           num_epochs = 30,\n",
    "           verbose = True)\n",
    "\n",
    "# CNN prediction\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "idx = np.random.choice(np.arange(len(y_test)), 100)\n",
    "X_test0 = X_test[idx, :]/np.max(X_test)\n",
    "y_test0 = y_test[idx, :]\n",
    "\n",
    "out_test = []\n",
    "\n",
    "for i in range(X_test0.shape[0]):\n",
    "    out_test.append((X_test0[i,:].reshape(1,28+thickness,28+thickness)))\n",
    "                \n",
    "y_hat = CNN0.predict(image_list=out_test)\n",
    "\n",
    "y_test_label = np.asarray(onehot2list(y_test0))\n",
    "P_pred = np.asarray([p[1] for p in y_hat])\n",
    "\n",
    "compute_accuracy_metrics(Y_test=y_test_label, P_pred=P_pred, use_opt_threshold=False, verbose=True)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute comparative multiclass classification metrics on test data\n",
    "\n",
    "thinkness = 10\n",
    "n_filters = [2, 5, 10, 15, 20]\n",
    "list_digits=['0','1','2','3','4']\n",
    "\n",
    "# Data preprocessing\n",
    "\n",
    "X_train, X_test, y_train, y_test = sample_multiclass_MNIST_padding(list_digits=['0','1'], \n",
    "                                                                   full_MNIST=[X,y],\n",
    "                                                                   padding_thickness=thinkness)\n",
    "train_size_list = [1000, 50, 100]\n",
    "\n",
    "# make plot\n",
    "ncols = len(train_size_list)\n",
    "fig, ax = plt.subplots(nrows=1, ncols=ncols, figsize=[13,5])\n",
    "\n",
    "for t in np.arange(len(train_size_list)):\n",
    "    accuracy_list_test = []\n",
    "    accuracy_list_train = []\n",
    "    \n",
    "    train_size = train_size_list[t]\n",
    "    idx = np.random.choice(np.arange(len(y_train)), train_size)\n",
    "    X_train0 = X_train[idx, :]/np.max(X_train)\n",
    "    y_train0 = y_train[idx, :]\n",
    "    \n",
    "    idx = np.random.choice(np.arange(len(y_test)), 1000)\n",
    "    X_test0 = X_test[idx, :]/np.max(X_test)\n",
    "    y_test0 = y_test[idx, :]\n",
    "\n",
    "    out = []\n",
    "    out_train = []\n",
    "    # populate the tuple list with the data\n",
    "    for i in range(X_train0.shape[0]):\n",
    "        item = list((X_train0[i,:].reshape(1,28+thinkness,28+thinkness), y_train0[i,:])) \n",
    "        out.append(item)\n",
    "        out_train.append(X_train0[i,:].reshape(1,28+thinkness,28+thinkness))\n",
    "        \n",
    "    X_test /= np.max(X_test)\n",
    "    out_test = []\n",
    "    for i in range(X_test0.shape[0]):\n",
    "        out_test.append((X_test0[i,:].reshape(1,28+thinkness,28+thinkness)))\n",
    "\n",
    "    for M in n_filters:\n",
    "\n",
    "        # CNN training\n",
    "        CNN0 = CNN(training_data = out,\n",
    "           f = 5, # conv filter dim\n",
    "           f_pool = 2, # maxpool filter dim\n",
    "           num_filt1 = M, # num filters for the first conv layer\n",
    "           num_filt2 = M, # num filters for the second conv layer\n",
    "           conv_stride = 1,\n",
    "           pool_stride = 2,\n",
    "           hidden_nodes = 128)\n",
    "\n",
    "        CNN0.train(lr = 0.01,\n",
    "                   beta1 = 0.95,\n",
    "                   beta2 = 0.99,\n",
    "                   minibatch_size = 32,\n",
    "                   num_epochs = 100,\n",
    "                   verbose = True)\n",
    "        \n",
    "        # CNN prediction\n",
    "        print()\n",
    "        y_hat_train = np.asarray(CNN0.predict(out_train))\n",
    "        y_hat_test = np.asarray(CNN0.predict(out_test))\n",
    "\n",
    "        y_train_label = np.asarray(onehot2list(y_train0))\n",
    "        y_test_label = np.asarray(onehot2list(y_test0))\n",
    "\n",
    "        results_train = multiclass_accuracy_metrics(Y_test=y_train0, P_pred=y_hat_train)\n",
    "        results_test = multiclass_accuracy_metrics(Y_test=y_test0, P_pred=y_hat_test)\n",
    "\n",
    "        accuracy_list_train.append(results_train.get('Accuracy'))\n",
    "        accuracy_list_test.append(results_test.get('Accuracy'))\n",
    "    \n",
    "    ## Plot\n",
    "    ax[t].plot(n_filters, accuracy_list_train, color='blue', label=\"train accuracy\")\n",
    "    ax[t].plot(n_filters, accuracy_list_test, color='red', label=\"test accuracy\")\n",
    "    ax[t].set_xlabel('Number of filters', fontsize=15)\n",
    "    ax[t].set_ylabel('Classification Accuracy', fontsize=15)\n",
    "    ax[t].title.set_text(\"num training ex = %i\" % (train_size)) \n",
    "    ax[t].legend(fontsize=15)\n",
    "            \n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.9])\n",
    "plt.savefig('MNIST_CNN_accuracy_ex1.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying non-aligned MNIST images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute comparative multiclass classification metrics on test data\n",
    "\n",
    "padding_list = [0, 5, 10]\n",
    "# list_digits=['0','1','2','3','4']\n",
    "list_digits=['0','1']\n",
    "\n",
    "## Train\n",
    "train_size_list = [50, 100, 200]\n",
    "\n",
    "# make plot\n",
    "ncols = len(train_size_list)\n",
    "fig, ax = plt.subplots(nrows=1, ncols=ncols, figsize=[13,5])\n",
    "\n",
    "for t in np.arange(len(train_size_list)):\n",
    "    accuracy_list_test = []\n",
    "    accuracy_list_train = []\n",
    "    \n",
    "    train_size = train_size_list[t]\n",
    "    \n",
    "    for thickness in padding_list:\n",
    "        # Data preprocessing\n",
    "        X_train, X_test, y_train, y_test = sample_multiclass_MNIST_padding(list_digits=list_digits, \n",
    "                                                                           full_MNIST=[X,y], \n",
    "                                                                           padding_thickness=thickness)\n",
    "            \n",
    "        idx = np.random.choice(np.arange(len(y_train)), train_size)\n",
    "        X_train0 = X_train[idx, :]/np.max(X_train)\n",
    "        y_train0 = y_train[idx, :]\n",
    "\n",
    "        \n",
    "        \n",
    "        idx = np.random.choice(np.arange(len(y_test)), 100)\n",
    "        X_test0 = X_test[idx, :]/np.max(X_test)\n",
    "        y_test0 = y_test[idx, :]\n",
    "\n",
    "        out = []\n",
    "        out_train = []\n",
    "        # populate the tuple list with the data\n",
    "        for i in range(X_train0.shape[0]):\n",
    "            item = list((X_train0[i,:].reshape(1, 28+thickness, 28+thickness), y_train0[i,:])) \n",
    "            \n",
    "            out.append(item)\n",
    "            out_train.append(X_train0[i,:].reshape(1, 28+thickness, 28+thickness))\n",
    "\n",
    "        X_test /= np.max(X_test)\n",
    "        out_test = []\n",
    "        for i in range(X_test0.shape[0]):\n",
    "            out_test.append((X_test0[i,:].reshape(1, 28+thickness, 28+thickness)))\n",
    "    \n",
    "    \n",
    "    \n",
    "        # CNN training\n",
    "        CNN0 = CNN(training_data = out,\n",
    "           f = 5, # conv filter dim\n",
    "           f_pool = 2, # maxpool filter dim\n",
    "           num_filt1 = 10, # num filters for the first conv layer\n",
    "           num_filt2 = 10, # num filters for the second conv layer\n",
    "           conv_stride = 1,\n",
    "           pool_stride = 2,\n",
    "           hidden_nodes = 128)\n",
    "\n",
    "        CNN0.train(lr = 0.01,\n",
    "                   beta1 = 0.95,\n",
    "                   beta2 = 0.99,\n",
    "                   minibatch_size = 32,\n",
    "                   num_epochs = 50,\n",
    "                   verbose = True)\n",
    "\n",
    "        # CNN prediction\n",
    "        print()\n",
    "        y_hat_train = np.asarray(CNN0.predict(out_train))\n",
    "        y_hat_test = np.asarray(CNN0.predict(out_test))\n",
    "\n",
    "        y_train_label = np.asarray(onehot2list(y_train0))\n",
    "        y_test_label = np.asarray(onehot2list(y_test0))\n",
    "\n",
    "        results_train = multiclass_accuracy_metrics(Y_test=y_train0, P_pred=y_hat_train)\n",
    "        results_test = multiclass_accuracy_metrics(Y_test=y_test0, P_pred=y_hat_test)\n",
    "\n",
    "        accuracy_list_train.append(results_train.get('Accuracy'))\n",
    "        accuracy_list_test.append(results_test.get('Accuracy'))\n",
    "    \n",
    "    ## Plot\n",
    "    ax[t].plot(padding_list, accuracy_list_train, color='blue', label=\"train accuracy\")\n",
    "    ax[t].plot(padding_list, accuracy_list_test, color='red', label=\"test accuracy\")\n",
    "    ax[t].set_xlabel('Padding thickness', fontsize=15)\n",
    "    ax[t].set_ylabel('Classification Accuracy', fontsize=15)\n",
    "    ax[t].title.set_text(\"num training ex = %i\" % (train_size)) \n",
    "    ax[t].legend(fontsize=15)\n",
    "            \n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.9])\n",
    "plt.savefig('MNIST_CNN_accuracy_padding_ex3.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "colourgraphenv",
   "language": "python",
   "name": "colourgraphenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
