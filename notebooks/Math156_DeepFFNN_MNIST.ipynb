{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# from sklearn.utils.extmath import softmax\n",
    "from matplotlib import pyplot as plt\n",
    "import re\n",
    "from tqdm import trange\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "plt.rcParams['font.serif'] = ['Times New Roman'] + plt.rcParams['font.serif']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample implementation of FFNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "class DeepFFNN(object):\n",
    "    \"\"\"\n",
    "    Author: Hanbaek Lyu\n",
    "    Genearal Deep Feedforward Neural Network implementation \n",
    "    Input data type: training_data = [pattern1, pattern2, ..., pattern n]\n",
    "    Activation: tanh for hidden layer and sigmoid for output layer \n",
    "    \n",
    "    pattern i = [np.array (input), np.array (output)]\n",
    "    \n",
    "    TODO: Currently uses square loss. Should be easy to implement other loss functions. \n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 hidden_layer_sizes,  # input and output layer sizes read off from training data\n",
    "                 training_data,  # list of patterns [np.array (input), np.array (output)]\n",
    "                 activation_list=None): # desired list of activation functions in each layer. \n",
    "       \n",
    "        # initialize training data and layer info\n",
    "        self.training_data = training_data\n",
    "        self.activation_list = activation_list\n",
    "        self.list_layer_sizes = [len(self.training_data[0][0]) + 1] + hidden_layer_sizes + [len(self.training_data[0][1])]        \n",
    "        # add hidden unit in the input layer. No hidden units for the hidden layers. \n",
    "        self.n_layers = len(self.list_layer_sizes)-1\n",
    "        \n",
    "        self.initialize()\n",
    "        \n",
    "    def initialize(self):\n",
    "        \n",
    "        # list of activation functions\n",
    "        if self.activation_list is None:\n",
    "            activation_list = ['tanh' for i in np.arange(len(self.list_layer_sizes))]\n",
    "            activation_list[0] = 'identity'  # dummy activation for the input layer\n",
    "            activation_list[-1] = 'sigmoid'\n",
    "            self.activation_list = activation_list\n",
    "\n",
    "        # default activation of nodes\n",
    "        node_states = []\n",
    "        for i in np.arange(len(self.list_layer_sizes)):\n",
    "            node_states.append(np.zeros(shape=[self.list_layer_sizes[i], ]))\n",
    "        self.node_states = node_states\n",
    "        \n",
    "        # initial weight matrices \n",
    "        # use scheme from 'efficient backprop to initialize weights'\n",
    "        weight_matrices = []\n",
    "        for i in np.arange(self.n_layers):\n",
    "            weight_range = 1/(self.list_layer_sizes[i]**(0.5))\n",
    "            U = np.random.normal(loc = 0, scale = weight_range, size = (self.list_layer_sizes[i], self.list_layer_sizes[i+1]))\n",
    "            weight_matrices.append(U)\n",
    "            print('weight_matrix.shape', U.shape)\n",
    "        self.weight_matrices = weight_matrices\n",
    "           \n",
    "        # create arrays of 0's to store previous gradients for momentum term in SGD update \n",
    "        prev_grad_list = []\n",
    "        for i in np.arange(self.n_layers):\n",
    "            V = np.zeros((self.list_layer_sizes[i], self.list_layer_sizes[i+1]))\n",
    "            prev_grad_list.append(V)\n",
    "        self.prev_grad_list = prev_grad_list\n",
    "\n",
    "    def forwardPropagate(self, inputs):\n",
    "        # Forward propagate the input using the current weights and update node states \n",
    "        self.node_states[0][:-1] = inputs # avoid last coordinate for hidden unit \n",
    "        for i in np.arange(self.n_layers):    \n",
    "            X_new = self.node_states[i].T @ self.weight_matrices[i]\n",
    "            X_new = activation(X_new, type=self.activation_list[i+1])\n",
    "            self.node_states[i+1] = X_new\n",
    "        \n",
    "        return self.node_states[-1]\n",
    "\n",
    "    def backPropagate(self, targets):\n",
    "        \"\"\"\n",
    "        Backpropagate errors from the output to the input layer \n",
    "        Return gradients for the weight matrices\n",
    "        \"\"\"\n",
    "    \n",
    "        error_list = self.node_states.copy()\n",
    "        # error at the output layer to be backpropagated \n",
    "        error = -(np.asarray(targets) - np.asarray(self.node_states[-1]))\n",
    "        for L in range(self.n_layers, 0, -1): # layer index to be backpropagated \n",
    "            # print('L', L)\n",
    "            if L < self.n_layers: # Not backpropagating from the output layer\n",
    "                error = self.weight_matrices[L] @ error_list[L+1].reshape(-1,1)\n",
    "                error = error[:,0] \n",
    "            error_list[L] = delta_activation(self.node_states[L], type=self.activation_list[L]) * error\n",
    "            \n",
    "        # Compute the gradients\n",
    "        grad_list = self.weight_matrices.copy()\n",
    "        for i in np.arange(self.n_layers):\n",
    "            grad_list[i] = self.node_states[i].reshape(-1,1) @ error_list[i+1].reshape(1,-1) \n",
    "        \n",
    "        return grad_list\n",
    "\n",
    "\n",
    "    def train(self, iterations=100, learning_rate=0.5, momentum=0.5, rate_decay=0.01, verbose=True):\n",
    "        # N: learning rate\n",
    "        self.learning_rate = learning_rate\n",
    "        self.momentum = momentum\n",
    "        self.rate_decay = rate_decay\n",
    "        error = 10\n",
    "        i=0\n",
    "        while (i<iterations) and (error>0.001):\n",
    "            error = 0.0\n",
    "            random.shuffle(self.training_data)\n",
    "            for p in self.training_data:\n",
    "                inputs = p[0]\n",
    "                targets = p[1]\n",
    "                self.forwardPropagate(inputs)\n",
    "                grad_list = self.backPropagate(targets)\n",
    "                \n",
    "                for L in np.arange(self.n_layers):\n",
    "                    # update the L th weight matrix connecting L th and (L+1)st layers \n",
    "                    grad = grad_list[L]\n",
    "                    prev_grad = self.prev_grad_list[L]\n",
    "                    self.weight_matrices[L] -= self.learning_rate * grad + self.momentum * prev_grad\n",
    "                    self.prev_grad_list[L] = grad # store current gradient \n",
    "        \n",
    "                error += (0.5) * np.linalg.norm(np.asarray(targets) - self.node_states[-1])**2\n",
    "            \n",
    "            with open('error.txt', 'a') as errorfile:\n",
    "                errorfile.write(str(error) + '\\n')\n",
    "                errorfile.close()\n",
    "                \n",
    "            if (i % 5 == 0) and verbose:\n",
    "                print('iteration %i, error %-.5f' % (i, error))\n",
    "            # learning rate decay\n",
    "            self.learning_rate = 1/(np.log(i+2) * (i+50)**(0.5))\n",
    "            # self.learning_rate = self.learning_rate * (self.learning_rate / (self.learning_rate + (self.learning_rate * self.rate_decay)))\n",
    "            \n",
    "            i += 1  \n",
    "        \n",
    "    \n",
    "    def predict(self, X, normalize = False):\n",
    "        X = np.asarray(X).T\n",
    "        x = np.vstack((np.asarray(X), np.ones(X.shape[1]))) # add 1 for hidden units in the input layer\n",
    "        print('X.shape', X.shape)\n",
    "    \n",
    "        for i in np.arange(self.n_layers):    \n",
    "            x = x.T @ self.weight_matrices[i]\n",
    "            x = activation(x.T, type=self.activation_list[i+1])\n",
    "            \n",
    "        print('y_hat.shape', x.shape)\n",
    "        return x\n",
    "    \n",
    "### Helper functions     \n",
    "    \n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# derivative of sigmoid\n",
    "def dsigmoid(y):\n",
    "    return y * (1.0 - y)\n",
    "\n",
    "# using tanh over logistic sigmoid is recommended   \n",
    "\n",
    "def tanh(x):\n",
    "    return (1-np.exp(-2*x))/(1+np.exp(-2*x))\n",
    "    # return np.tanh(x)\n",
    "    \n",
    "# derivative for tanh sigmoid\n",
    "def dtanh(y):\n",
    "    return 1 - y*y\n",
    "\n",
    "\n",
    "### Helper functions\n",
    "\n",
    "def loss_function(y, y_hat, type='cross-entropy'):\n",
    "    \"\"\"\n",
    "    y_hat = column array of predictive PMF \n",
    "    y = column array of one-hot encoding of true class label\n",
    "    \"\"\"\n",
    "    if type == 'cross_entropy':\n",
    "        return cross_entropy(y=y, y_hat=y_hat)\n",
    "    elif type == 'square':\n",
    "        return (1/2) * (y_hat - y).T @ (y_hat - y)\n",
    "    elif type == 'softmax-cross-entropy':\n",
    "        return cross_entropy(y=y, y_hat=softmax(y_hat))\n",
    "   \n",
    "\n",
    "def delta_loss_function(y, y_hat, type='cross-entropy'):\n",
    "    \"\"\"\n",
    "    y_hat = column array of predictive PMF \n",
    "    y = column array of one-hot encoding of true class label\n",
    "    \"\"\"\n",
    "    # return delta_cross_entropy(y=y, y_hat=y_hat/np.sum(y_hat))\n",
    "    \n",
    "    if type == 'cross-entropy':\n",
    "        return delta_cross_entropy(y=y, y_hat=y_hat)\n",
    "    elif type == 'square':\n",
    "        return y_hat - y\n",
    "    elif type == 'softmax-cross-entropy':\n",
    "        return softmax(y_hat) - y\n",
    "\n",
    "        \n",
    "def activation(x, type='sigmoid'):\n",
    "    if type == 'sigmoid':\n",
    "        return 1/(1+np.exp(-x))\n",
    "    elif type == 'ReLU':\n",
    "        return np.maximum(0,x)\n",
    "    elif type == 'tanh':\n",
    "        return tanh(x)\n",
    "    elif type == 'identity':\n",
    "        return x\n",
    "    \n",
    "def delta_activation(y, type='sigmoid'):\n",
    "    # derivate of activation function\n",
    "    if type == 'sigmoid':\n",
    "        return y*(1-y)\n",
    "    elif type == 'ReLU':\n",
    "        return int((y>0))\n",
    "    elif type == 'tanh':\n",
    "        return 1-y**2\n",
    "    elif type == 'identity':\n",
    "        return 1\n",
    "        \n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def ReLU(x):\n",
    "    return np.maximum(0,x)\n",
    "\n",
    "\n",
    "def softmax(x):\n",
    "    exps = np.exp(x - np.max(x))\n",
    "    return exps / np.sum(exps)\n",
    "\n",
    "def cross_entropy(y, y_hat):\n",
    "    \"\"\"\n",
    "    y_hat = column array of predictive PMF \n",
    "    y = column array of one-hot encoding of true class label\n",
    "    \"\"\"\n",
    "    return -(y.T @ np.log(y_hat))[0][0]\n",
    "\n",
    "def delta_cross_entropy(y, y_hat):\n",
    "    \"\"\"\n",
    "    y_hat = column array of predictive PMF \n",
    "    y = column array of one-hot encoding of true class label\n",
    "    \"\"\"\n",
    "    y_hat /= np.max(y_hat)\n",
    "    z = y.copy()\n",
    "    for i in np.arange(y.shape[0]):\n",
    "        a = y.argmax(axis=0)[0]\n",
    "        z[i,0] = -1/y_hat[a, 0]\n",
    "    return z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying MNIST images using FFNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list2onehot(y, list_classes):\n",
    "    \"\"\"\n",
    "    y = list of class lables of length n\n",
    "    output = n x k array, i th row = one-hot encoding of y[i] (e.g., [0,0,1,0,0])\n",
    "    \"\"\"\n",
    "    Y = np.zeros(shape = [len(y), len(list_classes)], dtype=int)\n",
    "    for i in np.arange(Y.shape[0]):\n",
    "        for j in np.arange(len(list_classes)):\n",
    "            if y[i] == list_classes[j]:\n",
    "                Y[i,j] = 1\n",
    "    return Y\n",
    "\n",
    "def onehot2list(y, list_classes=None):\n",
    "    \"\"\"\n",
    "    y = n x k array, i th row = one-hot encoding of y[i] (e.g., [0,0,1,0,0])\n",
    "    output =  list of class lables of length n\n",
    "    \"\"\"\n",
    "    if list_classes is None:\n",
    "        list_classes = np.arange(y.shape[1])\n",
    "        \n",
    "    y_list = []\n",
    "    for i in np.arange(y.shape[0]):\n",
    "        idx = np.where(y[i,:]==1)\n",
    "        idx = idx[0][0]\n",
    "        y_list.append(list_classes[idx])\n",
    "    return y_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape (70000, 784)\n",
      "y.shape (70000,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nEach row of X is a vectroization of an image of 28 x 28 = 784 pixels.  \\nThe corresponding row of y holds the true class label from {0,1, .. , 9}.\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data from https://www.openml.org/d/554\n",
    "X, y = fetch_openml('mnist_784', version=1, return_X_y=True)\n",
    "# X = X.values  ### Uncomment this line if you are having type errors in plotting. It is loading as a pandas dataframe, but our indexing is for numpy array. \n",
    "X = X / 255.\n",
    "\n",
    "print('X.shape', X.shape)\n",
    "print('y.shape', y.shape)\n",
    "\n",
    "'''\n",
    "Each row of X is a vectroization of an image of 28 x 28 = 784 pixels.  \n",
    "The corresponding row of y holds the true class label from {0,1, .. , 9}.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_multiclass_MNIST(list_digits=['0','1', '2'], full_MNIST=None):\n",
    "    # get train and test set from MNIST of given digits\n",
    "    # e.g., list_digits = ['0', '1', '2']\n",
    "    if full_MNIST is not None:\n",
    "        X, y = full_MNIST\n",
    "    else:\n",
    "        X, y = fetch_openml('mnist_784', version=1, return_X_y=True)\n",
    "        X = X / 255.\n",
    "    Y = list2onehot(y.tolist(), list_digits)\n",
    "    \n",
    "    idx = [i for i in np.arange(len(y)) if y[i] in list_digits] # list of indices where the label y is in list_digits\n",
    "    \n",
    "    X01 = X[idx,:]\n",
    "    y01 = Y[idx,:]\n",
    "\n",
    "    X_train = []\n",
    "    X_test = []\n",
    "    y_test = [] # list of one-hot encodings (indicator vectors) of each label  \n",
    "    y_train = [] # list of one-hot encodings (indicator vectors) of each label  \n",
    "\n",
    "    for i in trange(X01.shape[0]):\n",
    "        # for each example i, make it into train set with probabiliy 0.8 and into test set otherwise \n",
    "        U = np.random.rand() # Uniform([0,1]) variable\n",
    "        if U<0.8:\n",
    "            X_train.append(X01[i,:])\n",
    "            y_train.append(y01[i,:].copy())\n",
    "        else:\n",
    "            X_test.append(X01[i,:])\n",
    "            y_test.append(y01[i,:].copy())\n",
    "\n",
    "    X_train = np.asarray(X_train)\n",
    "    X_test = np.asarray(X_test)\n",
    "    y_train = np.asarray(y_train)\n",
    "    y_test = np.asarray(y_test)\n",
    "    return X_train, X_test, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy_metrics(Y_test, P_pred, use_opt_threshold=False, verbose=True):\n",
    "    \n",
    "    # y_test = binary label \n",
    "    # P_pred = predicted probability for y_test\n",
    "    # compuate various binary classification accuracy metrics\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(Y_test, P_pred, pos_label=None)\n",
    "    mythre = thresholds[np.argmax(tpr - fpr)]\n",
    "    myauc = metrics.auc(fpr, tpr)\n",
    "    # print('!!! auc', myauc)\n",
    "    \n",
    "    # Compute classification statistics\n",
    "    threshold = 0.5\n",
    "    if use_opt_threshold:\n",
    "        threshold = mythre\n",
    "    \n",
    "    Y_pred = P_pred.copy()\n",
    "    Y_pred[Y_pred < threshold] = 0\n",
    "    Y_pred[Y_pred >= threshold] = 1\n",
    "\n",
    "    mcm = confusion_matrix(Y_test, Y_pred)\n",
    "    \n",
    "    tn = mcm[0, 0]\n",
    "    tp = mcm[1, 1]\n",
    "    fn = mcm[1, 0]\n",
    "    fp = mcm[0, 1]\n",
    "\n",
    "    accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "    sensitivity = tn / (tn + fp)\n",
    "    specificity = tp / (tp + fn)\n",
    "    precision = tp / (tp + fp)\n",
    "    fall_out = fp / (fp + tn)\n",
    "    miss_rate = fn / (fn + tp)\n",
    "\n",
    "    # Save results\n",
    "    results_dict = {}\n",
    "    results_dict.update({'Y_test': Y_test})\n",
    "    results_dict.update({'Y_pred': Y_pred})\n",
    "    results_dict.update({'AUC': myauc})\n",
    "    results_dict.update({'Opt_threshold': mythre})\n",
    "    results_dict.update({'Accuracy': accuracy})\n",
    "    results_dict.update({'Sensitivity': sensitivity})\n",
    "    results_dict.update({'Specificity': specificity})\n",
    "    results_dict.update({'Precision': precision})\n",
    "    results_dict.update({'Fall_out': fall_out})\n",
    "    results_dict.update({'Miss_rate': miss_rate})\n",
    "    results_dict.update({'Confusion_mx': mcm})\n",
    "    \n",
    "    \n",
    "    if verbose:\n",
    "        for key in [key for key in results_dict.keys()]:\n",
    "            if key not in ['Y_test', 'Y_pred', 'Confusion_mx']:\n",
    "                print('% s ===> %.3f' % (key, results_dict.get(key)))\n",
    "        print('Confusion matrix  ===> \\n', mcm)\n",
    "            \n",
    "    return results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiclass_accuracy_metrics(Y_test, P_pred, class_labels=None, use_opt_threshold=False):\n",
    "    # y_test = multiclass one-hot encoding  labels [samples x labels]\n",
    "    # Q = predicted probability for y_test\n",
    "    # compuate various classification accuracy metrics\n",
    "    results_dict = {}\n",
    "    y_test = []\n",
    "    y_pred = []\n",
    "    for i in np.arange(Y_test.shape[0]):\n",
    "        for j in np.arange(Y_test.shape[1]):\n",
    "            if Y_test[i,j] == 1:\n",
    "                y_test.append(j)\n",
    "            if P_pred[i,j] == np.max(P_pred[i,:]):\n",
    "                # print('!!!', np.where(P_pred[i,:]==np.max(P_pred[i,:])))\n",
    "                y_pred.append(j)\n",
    "            \n",
    "    confusion_mx = metrics.confusion_matrix(y_test, y_pred)\n",
    "    results_dict.update({'confusion_mx':confusion_mx})\n",
    "    results_dict.update({'Accuracy':np.trace(confusion_mx)/np.sum(np.sum(confusion_mx))})\n",
    "    print('!!! confusion_mx', confusion_mx)\n",
    "    print('!!! Accuracy', results_dict.get('Accuracy'))\n",
    "    \n",
    "    \n",
    "    return results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14780/14780 [00:00<00:00, 479367.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight_matrix.shape (785, 10)\n",
      "weight_matrix.shape (10, 2)\n",
      "iteration 0, error 2.01882\n",
      "iteration 5, error 0.05751\n",
      "iteration 10, error 0.04361\n",
      "iteration 15, error 0.03672\n",
      "iteration 20, error 0.03235\n",
      "iteration 25, error 0.02924\n",
      "iteration 30, error 0.02689\n",
      "iteration 35, error 0.02503\n",
      "iteration 40, error 0.02351\n",
      "iteration 45, error 0.02223\n",
      "iteration 50, error 0.02115\n",
      "iteration 55, error 0.02021\n",
      "iteration 60, error 0.01939\n",
      "iteration 65, error 0.01866\n",
      "iteration 70, error 0.01801\n",
      "iteration 75, error 0.01742\n",
      "iteration 80, error 0.01689\n",
      "iteration 85, error 0.01641\n",
      "iteration 90, error 0.01596\n",
      "iteration 95, error 0.01556\n",
      "X.shape (784, 2905)\n",
      "y_hat.shape (2, 2905)\n",
      "AUC ===> 1.000\n",
      "Opt_threshold ===> 0.215\n",
      "Accuracy ===> 0.996\n",
      "Sensitivity ===> 0.996\n",
      "Specificity ===> 0.995\n",
      "Precision ===> 0.996\n",
      "Fall_out ===> 0.004\n",
      "Miss_rate ===> 0.005\n",
      "Confusion matrix  ===> \n",
      " [[1361    6]\n",
      " [   7 1531]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Y_test': array([1, 1, 0, ..., 0, 1, 1]),\n",
       " 'Y_pred': array([1., 0., 0., ..., 0., 1., 1.]),\n",
       " 'AUC': 0.9999148610713426,\n",
       " 'Opt_threshold': 0.21490298222598594,\n",
       " 'Accuracy': 0.9955249569707401,\n",
       " 'Sensitivity': 0.9956108266276518,\n",
       " 'Specificity': 0.9954486345903771,\n",
       " 'Precision': 0.996096291476903,\n",
       " 'Fall_out': 0.0043891733723482075,\n",
       " 'Miss_rate': 0.004551365409622887,\n",
       " 'Confusion_mx': array([[1361,    6],\n",
       "        [   7, 1531]])}"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simple MNIST binary classification experiments \n",
    "\n",
    "X_train, X_test, y_train, y_test = sample_multiclass_MNIST(list_digits=['0','1'], full_MNIST=[X,y])\n",
    "3\n",
    "# data subsampling \n",
    "train_size = 100\n",
    "\n",
    "idx = np.random.choice(np.arange(len(y_train)), train_size)\n",
    "X_train0 = X_train[idx, :]/np.max(X_train)\n",
    "y_train0 = y_train[idx, :]\n",
    "\n",
    "# preprocessing \n",
    "out = []\n",
    "# populate the tuple list with the data\n",
    "for i in range(X_train0.shape[0]):\n",
    "    item = list((X_train0[i,:], y_train0[i,:])) # don't mind this variable name\n",
    "    out.append(item)\n",
    "\n",
    "# FFNN training\n",
    "NN = DeepFFNN(hidden_layer_sizes=[10], training_data = out)\n",
    "NN.train(iterations=100, learning_rate = 0.5, momentum = 0, rate_decay = 0.01)\n",
    "\n",
    "#NN = MLP_NeuralNetwork_fast(hidden=M, training_data = out)\n",
    "#NN.train(iterations=100, learning_rate = 0.5, momentum = 0, rate_decay = 0.01)\n",
    "\n",
    "# FFNN prediction\n",
    "\n",
    "X_test /= np.max(X_test)\n",
    "out_test = []\n",
    "for i in range(X_test.shape[0]):\n",
    "    out_test.append(X_test[i,:].tolist())\n",
    "\n",
    "y_hat = NN.predict(out_test).T\n",
    "y_test_label = np.asarray(onehot2list(y_test))\n",
    "P_pred = np.asarray([p[1] for p in y_hat])\n",
    "\n",
    "compute_accuracy_metrics(Y_test=y_test_label, P_pred=P_pred, use_opt_threshold=False, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35735/35735 [00:00<00:00, 656712.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight_matrix.shape (785, 2)\n",
      "weight_matrix.shape (2, 5)\n",
      "iteration 0, error 4.29176\n",
      "iteration 5, error 3.83471\n",
      "iteration 10, error 3.79629\n",
      "iteration 15, error 3.76860\n",
      "iteration 20, error 3.74254\n",
      "iteration 25, error 3.71992\n",
      "iteration 30, error 3.70107\n",
      "iteration 35, error 3.68469\n",
      "iteration 40, error 3.66949\n",
      "iteration 45, error 3.65498\n",
      "iteration 50, error 3.64098\n",
      "iteration 55, error 3.62745\n",
      "iteration 60, error 3.61427\n",
      "iteration 65, error 3.60141\n",
      "iteration 70, error 3.58880\n",
      "iteration 75, error 3.57640\n",
      "iteration 80, error 3.56418\n",
      "iteration 85, error 3.55210\n",
      "iteration 90, error 3.54016\n",
      "iteration 95, error 3.52833\n",
      "\n",
      "X.shape (784, 10)\n",
      "y_hat.shape (5, 10)\n",
      "X.shape (784, 7062)\n",
      "y_hat.shape (5, 7062)\n",
      "!!! confusion_mx [[0 0 2 0]\n",
      " [0 3 0 0]\n",
      " [0 0 2 0]\n",
      " [0 3 0 0]]\n",
      "!!! Accuracy 0.5\n",
      "!!! confusion_mx [[   0    0 1387    0    0]\n",
      " [   0    0  506  787  264]\n",
      " [   0    0 1324   24   19]\n",
      " [   0    0  995  273  177]\n",
      " [   0    0 1219   44   43]]\n",
      "!!! Accuracy 0.23222883035967148\n",
      "weight_matrix.shape (785, 5)\n",
      "weight_matrix.shape (5, 5)\n",
      "iteration 0, error 5.14457\n",
      "iteration 5, error 2.11479\n",
      "iteration 10, error 1.89212\n",
      "iteration 15, error 1.76996\n",
      "iteration 20, error 1.68447\n",
      "iteration 25, error 1.61613\n",
      "iteration 30, error 1.55423\n",
      "iteration 35, error 1.48650\n",
      "iteration 40, error 1.39702\n",
      "iteration 45, error 1.32636\n",
      "iteration 50, error 1.28657\n",
      "iteration 55, error 1.25319\n",
      "iteration 60, error 1.22286\n",
      "iteration 65, error 1.19485\n",
      "iteration 70, error 1.16876\n",
      "iteration 75, error 1.14423\n",
      "iteration 80, error 1.12092\n",
      "iteration 85, error 1.09863\n",
      "iteration 90, error 1.07706\n",
      "iteration 95, error 1.05594\n",
      "\n",
      "X.shape (784, 10)\n",
      "y_hat.shape (5, 10)\n",
      "X.shape (784, 7062)\n",
      "y_hat.shape (5, 7062)\n",
      "!!! confusion_mx [[2 0 0 0]\n",
      " [0 3 0 0]\n",
      " [0 0 2 0]\n",
      " [0 0 0 3]]\n",
      "!!! Accuracy 1.0\n",
      "!!! confusion_mx [[   0    0 1138  147  102]\n",
      " [   0  529  516  506    6]\n",
      " [   0    2 1084  140  141]\n",
      " [   0    1  280 1134   30]\n",
      " [   0    0   93   83 1130]]\n",
      "!!! Accuracy 0.548994619088077\n",
      "weight_matrix.shape (785, 10)\n",
      "weight_matrix.shape (10, 5)\n",
      "iteration 0, error 4.07652\n",
      "iteration 5, error 1.65433\n",
      "iteration 10, error 1.14340\n",
      "iteration 15, error 0.85818\n",
      "iteration 20, error 0.69871\n",
      "iteration 25, error 0.59576\n",
      "iteration 30, error 0.52300\n",
      "iteration 35, error 0.46869\n",
      "iteration 40, error 0.42649\n",
      "iteration 45, error 0.39267\n",
      "iteration 50, error 0.36493\n",
      "iteration 55, error 0.34171\n",
      "iteration 60, error 0.32198\n",
      "iteration 65, error 0.30497\n",
      "iteration 70, error 0.29014\n",
      "iteration 75, error 0.27708\n",
      "iteration 80, error 0.26548\n",
      "iteration 85, error 0.25510\n",
      "iteration 90, error 0.24575\n",
      "iteration 95, error 0.23728\n",
      "\n",
      "X.shape (784, 10)\n",
      "y_hat.shape (5, 10)\n",
      "X.shape (784, 7062)\n",
      "y_hat.shape (5, 7062)\n",
      "!!! confusion_mx [[2 0 0 0]\n",
      " [0 3 0 0]\n",
      " [0 0 2 0]\n",
      " [0 0 0 3]]\n",
      "!!! Accuracy 1.0\n",
      "!!! confusion_mx [[   0   13  831  195  348]\n",
      " [   0 1357  188    9    3]\n",
      " [   0   99  919   84  265]\n",
      " [   0   65  236 1049   95]\n",
      " [   0   61    6    8 1231]]\n",
      "!!! Accuracy 0.6451430189747946\n",
      "weight_matrix.shape (785, 15)\n",
      "weight_matrix.shape (15, 5)\n",
      "iteration 0, error 4.72016\n",
      "iteration 5, error 1.11742\n",
      "iteration 10, error 0.79898\n",
      "iteration 15, error 0.62925\n",
      "iteration 20, error 0.52082\n",
      "iteration 25, error 0.44541\n",
      "iteration 30, error 0.39061\n",
      "iteration 35, error 0.34921\n",
      "iteration 40, error 0.31688\n",
      "iteration 45, error 0.29091\n",
      "iteration 50, error 0.26959\n",
      "iteration 55, error 0.25175\n",
      "iteration 60, error 0.23659\n",
      "iteration 65, error 0.22354\n",
      "iteration 70, error 0.21218\n",
      "iteration 75, error 0.20220\n",
      "iteration 80, error 0.19335\n",
      "iteration 85, error 0.18545\n",
      "iteration 90, error 0.17834\n",
      "iteration 95, error 0.17191\n",
      "\n",
      "X.shape (784, 10)\n",
      "y_hat.shape (5, 10)\n",
      "X.shape (784, 7062)\n",
      "y_hat.shape (5, 7062)\n",
      "!!! confusion_mx [[2 0 0 0]\n",
      " [0 3 0 0]\n",
      " [0 0 2 0]\n",
      " [0 0 0 3]]\n",
      "!!! Accuracy 1.0\n",
      "!!! confusion_mx [[   0    3 1033  235  116]\n",
      " [   0 1267  282    8    0]\n",
      " [   0   68 1077   63  159]\n",
      " [   0   46  299 1054   46]\n",
      " [   0   95   36    9 1166]]\n",
      "!!! Accuracy 0.6462758425375248\n",
      "weight_matrix.shape (785, 20)\n",
      "weight_matrix.shape (20, 5)\n",
      "iteration 0, error 4.97791\n",
      "iteration 5, error 0.77179\n",
      "iteration 10, error 0.51634\n",
      "iteration 15, error 0.40232\n",
      "iteration 20, error 0.33504\n",
      "iteration 25, error 0.28996\n",
      "iteration 30, error 0.25733\n",
      "iteration 35, error 0.23247\n",
      "iteration 40, error 0.21282\n",
      "iteration 45, error 0.19688\n",
      "iteration 50, error 0.18365\n",
      "iteration 55, error 0.17249\n",
      "iteration 60, error 0.16295\n",
      "iteration 65, error 0.15468\n",
      "iteration 70, error 0.14745\n",
      "iteration 75, error 0.14106\n",
      "iteration 80, error 0.13537\n",
      "iteration 85, error 0.13027\n",
      "iteration 90, error 0.12566\n",
      "iteration 95, error 0.12148\n",
      "\n",
      "X.shape (784, 10)\n",
      "y_hat.shape (5, 10)\n",
      "X.shape (784, 7062)\n",
      "y_hat.shape (5, 7062)\n",
      "!!! confusion_mx [[2 0 0 0]\n",
      " [0 3 0 0]\n",
      " [0 0 2 0]\n",
      " [0 0 0 3]]\n",
      "!!! Accuracy 1.0\n",
      "!!! confusion_mx [[   0    6  924  271  186]\n",
      " [   0 1331  216    8    2]\n",
      " [   0   97 1025   81  164]\n",
      " [   0   48  200 1140   57]\n",
      " [   0   49   26    9 1222]]\n",
      "!!! Accuracy 0.6680826961200793\n",
      "weight_matrix.shape (785, 2)\n",
      "weight_matrix.shape (2, 5)\n",
      "iteration 0, error 23.01391\n",
      "iteration 5, error 16.15892\n",
      "iteration 10, error 15.48547\n",
      "iteration 15, error 15.13550\n",
      "iteration 20, error 14.87376\n",
      "iteration 25, error 14.63429\n",
      "iteration 30, error 14.44112\n",
      "iteration 35, error 14.29275\n",
      "iteration 40, error 14.17821\n",
      "iteration 45, error 14.08474\n",
      "iteration 50, error 14.00315\n",
      "iteration 55, error 13.93438\n",
      "iteration 60, error 13.87389\n",
      "iteration 65, error 13.82006\n",
      "iteration 70, error 13.77206\n",
      "iteration 75, error 13.72767\n",
      "iteration 80, error 13.68743\n",
      "iteration 85, error 13.64918\n",
      "iteration 90, error 13.61266\n",
      "iteration 95, error 13.57736\n",
      "\n",
      "X.shape (784, 50)\n",
      "y_hat.shape (5, 50)\n",
      "X.shape (784, 7062)\n",
      "y_hat.shape (5, 7062)\n",
      "!!! confusion_mx [[ 0  5  1  0  0]\n",
      " [ 0 12  0  0  0]\n",
      " [ 0  0 13  0  0]\n",
      " [ 0  0  9  0  0]\n",
      " [ 0  0  0  0 10]]\n",
      "!!! Accuracy 0.7\n",
      "!!! confusion_mx [[   0  221  893    0  273]\n",
      " [   0  770  534    0  253]\n",
      " [   0   52 1260    0   55]\n",
      " [   0  126 1227    0   92]\n",
      " [   0   62   68    0 1176]]\n",
      "!!! Accuracy 0.4539790427640895\n",
      "weight_matrix.shape (785, 5)\n",
      "weight_matrix.shape (5, 5)\n",
      "iteration 0, error 20.16361\n",
      "iteration 5, error 9.11822\n",
      "iteration 10, error 6.72187\n",
      "iteration 15, error 5.58015\n",
      "iteration 20, error 4.86961\n",
      "iteration 25, error 4.37662\n",
      "iteration 30, error 4.00592\n",
      "iteration 35, error 3.71474\n",
      "iteration 40, error 3.48183\n",
      "iteration 45, error 3.29075\n",
      "iteration 50, error 3.13000\n",
      "iteration 55, error 2.99213\n",
      "iteration 60, error 2.87193\n",
      "iteration 65, error 2.76545\n",
      "iteration 70, error 2.66995\n",
      "iteration 75, error 2.58394\n",
      "iteration 80, error 2.50513\n",
      "iteration 85, error 2.43383\n",
      "iteration 90, error 2.36816\n",
      "iteration 95, error 2.30798\n",
      "\n",
      "X.shape (784, 50)\n",
      "y_hat.shape (5, 50)\n",
      "X.shape (784, 7062)\n",
      "y_hat.shape (5, 7062)\n",
      "!!! confusion_mx [[ 6  0  0  0  0]\n",
      " [ 0 12  0  0  0]\n",
      " [ 0  0 13  0  0]\n",
      " [ 0  0  1  8  0]\n",
      " [ 0  0  0  0 10]]\n",
      "!!! Accuracy 0.98\n",
      "!!! confusion_mx [[1209    4   67   87   20]\n",
      " [   0 1520   31    5    1]\n",
      " [  31  145 1148   24   19]\n",
      " [  43  263  223  877   39]\n",
      " [ 127  114   36    0 1029]]\n",
      "!!! Accuracy 0.8188898329085245\n",
      "weight_matrix.shape (785, 10)\n",
      "weight_matrix.shape (10, 5)\n",
      "iteration 0, error 19.86206\n",
      "iteration 5, error 5.68034\n",
      "iteration 10, error 4.09376\n",
      "iteration 15, error 3.21133\n",
      "iteration 20, error 2.36821\n",
      "iteration 25, error 1.83508\n",
      "iteration 30, error 1.50647\n",
      "iteration 35, error 1.28206\n",
      "iteration 40, error 1.11950\n",
      "iteration 45, error 0.99773\n",
      "iteration 50, error 0.90313\n",
      "iteration 55, error 0.82785\n",
      "iteration 60, error 0.76612\n",
      "iteration 65, error 0.71455\n",
      "iteration 70, error 0.67074\n",
      "iteration 75, error 0.63296\n",
      "iteration 80, error 0.60000\n",
      "iteration 85, error 0.57093\n",
      "iteration 90, error 0.54511\n",
      "iteration 95, error 0.52195\n",
      "\n",
      "X.shape (784, 50)\n",
      "y_hat.shape (5, 50)\n",
      "X.shape (784, 7062)\n",
      "y_hat.shape (5, 7062)\n",
      "!!! confusion_mx [[ 6  0  0  0  0]\n",
      " [ 0 12  0  0  0]\n",
      " [ 0  0 13  0  0]\n",
      " [ 0  0  0  9  0]\n",
      " [ 0  0  0  0 10]]\n",
      "!!! Accuracy 1.0\n",
      "!!! confusion_mx [[1267    4   74   31   11]\n",
      " [   3 1476   23    6   49]\n",
      " [  26  125 1111   63   42]\n",
      " [  50   68  126  980  221]\n",
      " [   5   55   84    0 1162]]\n",
      "!!! Accuracy 0.8490512602662136\n",
      "weight_matrix.shape (785, 15)\n",
      "weight_matrix.shape (15, 5)\n",
      "iteration 0, error 18.08153\n",
      "iteration 5, error 3.99706\n",
      "iteration 10, error 2.94948\n",
      "iteration 15, error 2.08914\n",
      "iteration 20, error 1.51873\n",
      "iteration 25, error 1.16722\n",
      "iteration 30, error 0.94599\n",
      "iteration 35, error 0.79881\n",
      "iteration 40, error 0.69453\n",
      "iteration 45, error 0.61699\n",
      "iteration 50, error 0.55664\n",
      "iteration 55, error 0.50884\n",
      "iteration 60, error 0.46968\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 65, error 0.43726\n",
      "iteration 70, error 0.40990\n",
      "iteration 75, error 0.38660\n",
      "iteration 80, error 0.36637\n",
      "iteration 85, error 0.34868\n",
      "iteration 90, error 0.33308\n",
      "iteration 95, error 0.31912\n",
      "\n",
      "X.shape (784, 50)\n",
      "y_hat.shape (5, 50)\n",
      "X.shape (784, 7062)\n",
      "y_hat.shape (5, 7062)\n",
      "!!! confusion_mx [[ 6  0  0  0  0]\n",
      " [ 0 12  0  0  0]\n",
      " [ 0  0 13  0  0]\n",
      " [ 0  0  0  9  0]\n",
      " [ 0  0  0  0 10]]\n",
      "!!! Accuracy 1.0\n",
      "!!! confusion_mx [[1312    1   49   18    7]\n",
      " [   0 1423   36   16   82]\n",
      " [  30   66 1159   84   28]\n",
      " [  79   11  197 1090   68]\n",
      " [   5   27  105    0 1169]]\n",
      "!!! Accuracy 0.8712829226847918\n",
      "weight_matrix.shape (785, 20)\n",
      "weight_matrix.shape (20, 5)\n",
      "iteration 0, error 17.32598\n",
      "iteration 5, error 1.86630\n",
      "iteration 10, error 1.00375\n",
      "iteration 15, error 0.73098\n",
      "iteration 20, error 0.58582\n",
      "iteration 25, error 0.49432\n",
      "iteration 30, error 0.43124\n",
      "iteration 35, error 0.38478\n",
      "iteration 40, error 0.34904\n",
      "iteration 45, error 0.32055\n",
      "iteration 50, error 0.29730\n",
      "iteration 55, error 0.27791\n",
      "iteration 60, error 0.26149\n",
      "iteration 65, error 0.24735\n",
      "iteration 70, error 0.23505\n",
      "iteration 75, error 0.22423\n",
      "iteration 80, error 0.21464\n",
      "iteration 85, error 0.20606\n",
      "iteration 90, error 0.19834\n",
      "iteration 95, error 0.19136\n",
      "\n",
      "X.shape (784, 50)\n",
      "y_hat.shape (5, 50)\n",
      "X.shape (784, 7062)\n",
      "y_hat.shape (5, 7062)\n",
      "!!! confusion_mx [[ 6  0  0  0  0]\n",
      " [ 0 12  0  0  0]\n",
      " [ 0  0 13  0  0]\n",
      " [ 0  0  0  9  0]\n",
      " [ 0  0  0  0 10]]\n",
      "!!! Accuracy 1.0\n",
      "!!! confusion_mx [[1291    1   66   20    9]\n",
      " [   2 1440   40   11   64]\n",
      " [  21   79 1150   83   34]\n",
      " [  52   38  166 1066  123]\n",
      " [   4   31   93    0 1178]]\n",
      "!!! Accuracy 0.8673180402152365\n",
      "weight_matrix.shape (785, 2)\n",
      "weight_matrix.shape (2, 5)\n",
      "iteration 0, error 41.47948\n",
      "iteration 5, error 30.81668\n",
      "iteration 10, error 28.34435\n",
      "iteration 15, error 27.87637\n",
      "iteration 20, error 27.68332\n",
      "iteration 25, error 27.56547\n",
      "iteration 30, error 27.48380\n",
      "iteration 35, error 27.42540\n",
      "iteration 40, error 27.37830\n",
      "iteration 45, error 27.34193\n",
      "iteration 50, error 27.31228\n",
      "iteration 55, error 27.28537\n",
      "iteration 60, error 27.26345\n",
      "iteration 65, error 27.24390\n",
      "iteration 70, error 27.22506\n",
      "iteration 75, error 27.21110\n",
      "iteration 80, error 27.19828\n",
      "iteration 85, error 27.18569\n",
      "iteration 90, error 27.17385\n",
      "iteration 95, error 27.16341\n",
      "\n",
      "X.shape (784, 100)\n",
      "y_hat.shape (5, 100)\n",
      "X.shape (784, 7062)\n",
      "y_hat.shape (5, 7062)\n",
      "!!! confusion_mx [[ 0 17  0  0  0]\n",
      " [ 0 21  0  0  0]\n",
      " [ 0  0 28  0  0]\n",
      " [ 0 15  0  0  0]\n",
      " [ 0 19  0  0  0]]\n",
      "!!! Accuracy 0.49\n",
      "!!! confusion_mx [[   0 1215  172    0    0]\n",
      " [   0 1516   41    0    0]\n",
      " [   0  157 1210    0    0]\n",
      " [   0 1306  139    0    0]\n",
      " [   0 1232   72    0    2]]\n",
      "!!! Accuracy 0.3862928348909657\n",
      "weight_matrix.shape (785, 5)\n",
      "weight_matrix.shape (5, 5)\n",
      "iteration 0, error 35.55625\n",
      "iteration 5, error 14.01009\n",
      "iteration 10, error 6.95672\n",
      "iteration 15, error 5.19058\n",
      "iteration 20, error 4.29087\n",
      "iteration 25, error 3.72234\n",
      "iteration 30, error 3.33151\n",
      "iteration 35, error 3.03661\n",
      "iteration 40, error 2.80287\n",
      "iteration 45, error 2.61148\n",
      "iteration 50, error 2.45057\n",
      "iteration 55, error 2.31334\n",
      "iteration 60, error 2.19417\n",
      "iteration 65, error 2.08956\n",
      "iteration 70, error 1.99691\n",
      "iteration 75, error 1.91423\n",
      "iteration 80, error 1.83982\n",
      "iteration 85, error 1.77255\n",
      "iteration 90, error 1.71133\n",
      "iteration 95, error 1.65533\n",
      "\n",
      "X.shape (784, 100)\n",
      "y_hat.shape (5, 100)\n",
      "X.shape (784, 7062)\n",
      "y_hat.shape (5, 7062)\n",
      "!!! confusion_mx [[17  0  0  0  0]\n",
      " [ 0 21  0  0  0]\n",
      " [ 0  0 28  0  0]\n",
      " [ 0  0  0 15  0]\n",
      " [ 0  0  0  0 19]]\n",
      "!!! Accuracy 1.0\n",
      "!!! confusion_mx [[1308    1   40    9   29]\n",
      " [   1 1526   18    9    3]\n",
      " [  36   30 1131   62  108]\n",
      " [  90   39  148 1136   32]\n",
      " [  21   66   68    1 1150]]\n",
      "!!! Accuracy 0.8851600113282356\n",
      "weight_matrix.shape (785, 10)\n",
      "weight_matrix.shape (10, 5)\n",
      "iteration 0, error 26.46774\n",
      "iteration 5, error 3.22642\n",
      "iteration 10, error 1.65580\n",
      "iteration 15, error 1.14872\n",
      "iteration 20, error 0.94409\n",
      "iteration 25, error 0.81974\n",
      "iteration 30, error 0.73148\n",
      "iteration 35, error 0.66570\n",
      "iteration 40, error 0.61395\n",
      "iteration 45, error 0.57204\n",
      "iteration 50, error 0.53731\n",
      "iteration 55, error 0.50791\n",
      "iteration 60, error 0.48257\n",
      "iteration 65, error 0.46056\n",
      "iteration 70, error 0.44118\n",
      "iteration 75, error 0.42397\n",
      "iteration 80, error 0.40850\n",
      "iteration 85, error 0.39459\n",
      "iteration 90, error 0.38191\n",
      "iteration 95, error 0.37037\n",
      "\n",
      "X.shape (784, 100)\n",
      "y_hat.shape (5, 100)\n",
      "X.shape (784, 7062)\n",
      "y_hat.shape (5, 7062)\n",
      "!!! confusion_mx [[17  0  0  0  0]\n",
      " [ 0 21  0  0  0]\n",
      " [ 0  0 28  0  0]\n",
      " [ 0  0  0 15  0]\n",
      " [ 0  0  0  0 19]]\n",
      "!!! Accuracy 1.0\n",
      "!!! confusion_mx [[1343    0   25    1   18]\n",
      " [   6 1515   14   19    3]\n",
      " [  53   44 1188   48   34]\n",
      " [  25   26  113 1257   24]\n",
      " [   7   26   41    5 1227]]\n",
      "!!! Accuracy 0.924667233078448\n",
      "weight_matrix.shape (785, 15)\n",
      "weight_matrix.shape (15, 5)\n",
      "iteration 0, error 29.09548\n",
      "iteration 5, error 1.77378\n",
      "iteration 10, error 0.98228\n",
      "iteration 15, error 0.74905\n",
      "iteration 20, error 0.62138\n",
      "iteration 25, error 0.53744\n",
      "iteration 30, error 0.47779\n",
      "iteration 35, error 0.43293\n",
      "iteration 40, error 0.39785\n",
      "iteration 45, error 0.36953\n",
      "iteration 50, error 0.34615\n",
      "iteration 55, error 0.32641\n",
      "iteration 60, error 0.30951\n",
      "iteration 65, error 0.29483\n",
      "iteration 70, error 0.28196\n",
      "iteration 75, error 0.27054\n",
      "iteration 80, error 0.26035\n",
      "iteration 85, error 0.25116\n",
      "iteration 90, error 0.24285\n",
      "iteration 95, error 0.23527\n",
      "\n",
      "X.shape (784, 100)\n",
      "y_hat.shape (5, 100)\n",
      "X.shape (784, 7062)\n",
      "y_hat.shape (5, 7062)\n",
      "!!! confusion_mx [[17  0  0  0  0]\n",
      " [ 0 21  0  0  0]\n",
      " [ 0  0 28  0  0]\n",
      " [ 0  0  0 15  0]\n",
      " [ 0  0  0  0 19]]\n",
      "!!! Accuracy 1.0\n",
      "!!! confusion_mx [[1338    1   36    1   11]\n",
      " [   5 1522    9   14    7]\n",
      " [  42   43 1212   36   34]\n",
      " [  50   35  116 1216   28]\n",
      " [  18   28   56    2 1202]]\n",
      "!!! Accuracy 0.9190031152647975\n",
      "weight_matrix.shape (785, 20)\n",
      "weight_matrix.shape (20, 5)\n",
      "iteration 0, error 24.37860\n",
      "iteration 5, error 1.01687\n",
      "iteration 10, error 0.63246\n",
      "iteration 15, error 0.48224\n",
      "iteration 20, error 0.40015\n",
      "iteration 25, error 0.34714\n",
      "iteration 30, error 0.30961\n",
      "iteration 35, error 0.28131\n",
      "iteration 40, error 0.25909\n",
      "iteration 45, error 0.24106\n",
      "iteration 50, error 0.22607\n",
      "iteration 55, error 0.21346\n",
      "iteration 60, error 0.20261\n",
      "iteration 65, error 0.19318\n",
      "iteration 70, error 0.18488\n",
      "iteration 75, error 0.17751\n",
      "iteration 80, error 0.17092\n",
      "iteration 85, error 0.16499\n",
      "iteration 90, error 0.15960\n",
      "iteration 95, error 0.15470\n",
      "\n",
      "X.shape (784, 100)\n",
      "y_hat.shape (5, 100)\n",
      "X.shape (784, 7062)\n",
      "y_hat.shape (5, 7062)\n",
      "!!! confusion_mx [[17  0  0  0  0]\n",
      " [ 0 21  0  0  0]\n",
      " [ 0  0 28  0  0]\n",
      " [ 0  0  0 15  0]\n",
      " [ 0  0  0  0 19]]\n",
      "!!! Accuracy 1.0\n",
      "!!! confusion_mx [[1325    6   34    2   20]\n",
      " [   3 1524   15   11    4]\n",
      " [  32   53 1189   33   60]\n",
      " [  36   27   77 1258   47]\n",
      " [   4   22   32    3 1245]]\n",
      "!!! Accuracy 0.926224865477202\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 936x360 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# compute comparative multiclass classification metrics on test data\n",
    "\n",
    "M_list = [2, 5, 10, 15, 20]\n",
    "list_digits=['0','1','2','3','4']\n",
    "\n",
    "# Data preprocessing\n",
    "\n",
    "X_train, X_test, y_train, y_test = sample_multiclass_MNIST(list_digits=list_digits, full_MNIST=[X,y])\n",
    "\n",
    "## Train\n",
    "train_size_list = [10, 50, 100]\n",
    "\n",
    "# make plot\n",
    "ncols = len(train_size_list)\n",
    "fig, ax = plt.subplots(nrows=1, ncols=ncols, figsize=[13,5])\n",
    "\n",
    "for t in np.arange(len(train_size_list)):\n",
    "    accuracy_list_test = []\n",
    "    accuracy_list_train = []\n",
    "    \n",
    "    train_size = train_size_list[t]\n",
    "    idx = np.random.choice(np.arange(len(y_train)), train_size)\n",
    "    X_train0 = X_train[idx, :]/np.max(X_train)\n",
    "    y_train0 = y_train[idx, :]\n",
    "\n",
    "    out = []\n",
    "    out_train = []\n",
    "    # populate the tuple list with the data\n",
    "    for i in range(X_train0.shape[0]):\n",
    "        item = list((X_train0[i,:].tolist(), y_train0[i,:].tolist())) # don't mind this variable name\n",
    "        out.append(item)\n",
    "        out_train.append(X_train0[i,:].tolist())\n",
    "\n",
    "    X_test /= np.max(X_test)\n",
    "    out_test = []\n",
    "    for i in range(X_test.shape[0]):\n",
    "        out_test.append(X_test[i,:].tolist())\n",
    "\n",
    "    for M in M_list:\n",
    "\n",
    "        # FFNN training\n",
    "        NN = DeepFFNN(hidden_layer_sizes=[M], training_data = out)\n",
    "        NN.train(iterations=100, learning_rate = 0.5, momentum = 0, rate_decay = 0.01)\n",
    "        \n",
    "        # FFNN prediction\n",
    "        print()\n",
    "        y_hat_train = NN.predict(out_train, normalize=True)\n",
    "        y_hat_test = NN.predict(out_test, normalize=True)\n",
    "\n",
    "        y_train_label = np.asarray(onehot2list(y_train0))\n",
    "        y_test_label = np.asarray(onehot2list(y_test))\n",
    "\n",
    "        results_train = multiclass_accuracy_metrics(Y_test=y_train0, P_pred=y_hat_train.T)\n",
    "        results_test = multiclass_accuracy_metrics(Y_test=y_test, P_pred=y_hat_test.T)\n",
    "\n",
    "        accuracy_list_train.append(results_train.get('Accuracy'))\n",
    "        accuracy_list_test.append(results_test.get('Accuracy'))\n",
    "    \n",
    "    ## Plot\n",
    "    ax[t].plot(M_list, accuracy_list_train, color='blue', label=\"train accuracy\")\n",
    "    ax[t].plot(M_list, accuracy_list_test, color='red', label=\"test accuracy\")\n",
    "    ax[t].set_xlabel('Number of hidden nodes', fontsize=15)\n",
    "    ax[t].set_ylabel('Classification Accuracy', fontsize=15)\n",
    "    ax[t].title.set_text(\"num training ex = %i\" % (train_size)) \n",
    "    ax[t].legend(fontsize=15)\n",
    "            \n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.9])\n",
    "plt.savefig('MNIST_FFNN_accuracy_ex1.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "class MLP(object):\n",
    "    \"\"\"\n",
    "    Author: Hanbaek Lyu\n",
    "    Multilayer Perceptron (2-layer Feedforward Neural Network) implementation \n",
    "    Input data type: training_data = [pattern1, pattern2, ..., pattern n]\n",
    "    Activation: tanh for hidden layer and sigmoid for output layer \n",
    "    This 2-layer version should be easier to see what's going on than the deep FFNN code. \n",
    "    \n",
    "    pattern i = [np.array (input), np.array (output)]\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 hidden,\n",
    "                 training_data):\n",
    "       \n",
    "        # initialize training data\n",
    "        self.training_data = training_data\n",
    "        \n",
    "        # initialize layer sizes\n",
    "        self.input = len(training_data[0][0]) + 1 # add 1 for bias node\n",
    "        self.hidden = hidden\n",
    "        self.output = len(training_data[0][1])\n",
    "\n",
    "        # set up array of 1s for activations (node states)\n",
    "        self.ai = np.ones(self.input)\n",
    "        self.ah = np.ones(self.hidden)\n",
    "        self.ao = np.ones(self.output)\n",
    "\n",
    "        # create randomized weights\n",
    "        # use scheme from 'efficient backprop to initialize weights'\n",
    "        input_range = 1.0 / self.input ** (1/2)\n",
    "        output_range = 1.0 / self.hidden ** (1/2)\n",
    "        self.wi = np.random.normal(loc = 0, scale = input_range, size = (self.input, self.hidden))\n",
    "        self.wo = np.random.normal(loc = 0, scale = output_range, size = (self.hidden, self.output))\n",
    "        \n",
    "        # create arrays of 0's to store previous gradients for momentum term in SGD update \n",
    "        self.ci = np.zeros((self.input, self.hidden))\n",
    "        self.co = np.zeros((self.hidden, self.output))\n",
    "\n",
    "    def feedForward(self, inputs):    \n",
    "        # input activations\n",
    "        self.ai[:-1] = inputs # -1 is to avoid the bias \n",
    "        # hidden activations\n",
    "        self.ah = tanh(self.ai.T @ self.wi).T # hidden states \n",
    "        # output activations\n",
    "        self.ao = sigmoid(self.ah.T @ self.wo).T # output states \n",
    "        \n",
    "        return self.ao\n",
    "\n",
    "    def backPropagate(self, targets):\n",
    "        \"\"\"\n",
    "        Backpropagate errors from the output to the input layer \n",
    "        Return gradients for the weight matrices\n",
    "        \"\"\"\n",
    "\n",
    "        # calculate error terms for output\n",
    "        error = -(np.asarray(targets) - np.asarray(self.ao))\n",
    "        output_deltas = dsigmoid(np.asarray(self.ao)) * error\n",
    "        output_deltas.tolist()\n",
    "        \n",
    "        # calculate error terms for hidden\n",
    "        error = self.wo @ output_deltas.reshape(-1,1)\n",
    "        hidden_deltas = dtanh(self.ah.reshape(-1,1)) * error\n",
    "        hidden_deltas = hidden_deltas[:,0]\n",
    "            \n",
    "        # compute gradients \n",
    "        grad1 = self.ah.reshape(-1,1) @ output_deltas.reshape(1,-1) \n",
    "        grad0 = self.ai.reshape(-1,1) @ hidden_deltas.reshape(1,-1) \n",
    "        \n",
    "        return grad0, grad1\n",
    "\n",
    "    def test(self, patterns):\n",
    "        \"\"\"\n",
    "        Currently this will print out the targets next to the predictions.\n",
    "        Not useful for actual ML, just for visual inspection.\n",
    "        \"\"\"\n",
    "        for p in patterns:\n",
    "            print(p[1], '->', self.feedForward(p[0]))\n",
    "\n",
    "    def train(self, iterations=100, learning_rate=0.5, momentum=0.5, rate_decay=0.01):\n",
    "        # N: learning rate\n",
    "        self.learning_rate = learning_rate\n",
    "        self.momentum = momentum\n",
    "        self.rate_decay = rate_decay\n",
    "        error = 10\n",
    "        i=0\n",
    "        while (i<iterations) and (error>0.001):\n",
    "            error = 0.0\n",
    "            random.shuffle(self.training_data)\n",
    "            for p in self.training_data:\n",
    "                inputs = p[0]\n",
    "                targets = p[1]\n",
    "                self.feedForward(inputs)\n",
    "                grad0, grad1 =self.backPropagate(targets)\n",
    "            \n",
    "                # update the weights connecting hidden to output\n",
    "                self.wo -= self.learning_rate * grad1 + self.momentum * self.co\n",
    "                self.co = grad1 # store current gradient \n",
    "\n",
    "                # update the weights connecting input to hidden\n",
    "                self.wi -= self.learning_rate * grad0 + self.momentum * self.ci\n",
    "                self.ci = grad0 # store current gradient \n",
    "        \n",
    "                error += (0.5) * np.linalg.norm(np.asarray(targets) - self.ao)**2\n",
    "            \n",
    "            with open('error.txt', 'a') as errorfile:\n",
    "                errorfile.write(str(error) + '\\n')\n",
    "                errorfile.close()\n",
    "                \n",
    "            if i % 5 == 0:\n",
    "                print('iteration %i, error %-.5f' % (i, error))\n",
    "            # learning rate decay\n",
    "            self.learning_rate = 1/(np.log(i+2) * (i+50)**(0.5))\n",
    "            # self.learning_rate = self.learning_rate * (self.learning_rate / (self.learning_rate + (self.learning_rate * self.rate_decay)))\n",
    "            \n",
    "            i += 1    \n",
    "        \n",
    "    \n",
    "    def predict(self, X, normalize = False):\n",
    "        X = np.asarray(X).T\n",
    "        x = np.vstack((np.asarray(X), np.ones(X.shape[1]))) # add 1 for hidden units in the input layer\n",
    "       \n",
    "        W0 = self.wi\n",
    "        W1 = self.wo \n",
    "        z = tanh(x.T @ W0).T # hidden states \n",
    "        y_hat = sigmoid((z.T @ W1).T) # output states\n",
    "        \n",
    "        if normalize:\n",
    "            sum_of_cols = y_hat.sum(axis=0)\n",
    "            y_hat /= sum_of_cols[np.newaxis,:]\n",
    "        \n",
    "        return y_hat\n",
    "    \n",
    "### Helper functions     \n",
    "    \n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# derivative of sigmoid\n",
    "def dsigmoid(y):\n",
    "    return y * (1.0 - y)\n",
    "\n",
    "# using tanh over logistic sigmoid is recommended   \n",
    "\n",
    "def tanh(x):\n",
    "    return (1-np.exp(-2*x))/(1+np.exp(-2*x))\n",
    "    # return np.tanh(x)\n",
    "    \n",
    "# derivative for tanh sigmoid\n",
    "def dtanh(y):\n",
    "    return 1 - y*y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "colourgraphenv",
   "language": "python",
   "name": "colourgraphenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
